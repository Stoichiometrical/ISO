{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training and Selection",
   "id": "8a5b4c6cfddc2b5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook furthur processes the data to match specific requirements of difrent models.Various models are explored and evaluated and feature engineering is also carried out on the clean dataset",
   "id": "86abbd716044f23d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:05:56.276978Z",
     "start_time": "2024-07-29T18:05:51.796459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import the neccesary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gr\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tabulate import tabulate"
   ],
   "id": "a710faa13ad150b4",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:05:56.451216Z",
     "start_time": "2024-07-29T18:05:56.276978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"processed.csv\", parse_dates=['date'], index_col='date')\n",
    "df =df.asfreq('D')\n",
    "df =df[[\"quantity\"]]\n",
    "df.head()"
   ],
   "id": "b3dc5cb79c2516b8",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T05:43:09.733509Z",
     "start_time": "2024-07-18T05:43:09.422273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Merged max :\",  df.index.max())\n",
    "print(\"Merged min :\",  df.index.min())"
   ],
   "id": "f5c7b7b0b83baead",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model 1 : SARIMAX",
   "id": "6154434b5d4533c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model 2 and 3 : ARIMA & SES",
   "id": "86772cdbac9b200e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:02:08.873295Z",
     "start_time": "2024-07-22T20:02:04.859031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "\n",
    "# ARIMA Model\n",
    "def fit_arima(train_data, order):\n",
    "    model = ARIMA(train_data, order=order)\n",
    "    fit_model = model.fit()\n",
    "    return fit_model\n",
    "\n",
    "# Exponential Smoothing (Simple Exponential Smoothing)\n",
    "def fit_exponential_smoothing(train_data):\n",
    "    model = SimpleExpSmoothing(train_data)\n",
    "    fit_model = model.fit()\n",
    "    return fit_model\n",
    "\n",
    "# Forecasting and Evaluation Function\n",
    "def forecast_and_evaluate(model, test_data):\n",
    "    forecast_values = model.forecast(len(test_data))\n",
    "    mae = mean_absolute_error(test_data, forecast_values)\n",
    "    mape = mean_absolute_percentage_error(test_data, forecast_values)\n",
    "    return forecast_values, mae, mape\n",
    "\n",
    "# Fit ARIMA model\n",
    "arima_model = fit_arima(train['quantity'], order=(1, 1, 1))\n",
    "\n",
    "# Fit Exponential Smoothing model\n",
    "exp_smoothing_model = fit_exponential_smoothing(train['quantity'])\n",
    "\n",
    "# Forecast and evaluate ARIMA\n",
    "arima_forecast, arima_mae, arima_mape = forecast_and_evaluate(arima_model, test['quantity'])\n",
    "\n",
    "# Forecast and evaluate Exponential Smoothing\n",
    "exp_smoothing_forecast, exp_smoothing_mae, exp_smoothing_mape = forecast_and_evaluate(exp_smoothing_model, test['quantity'])\n",
    "\n",
    "# Print results\n",
    "print(f'ARIMA MAE: {arima_mae}, ARIMA MAPE: {arima_mape}')\n",
    "print(f'Exponential Smoothing MAE: {exp_smoothing_mae}, Exponential Smoothing MAPE: {exp_smoothing_mape}')\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index, train['quantity'], label='Train')\n",
    "plt.plot(test.index, test['quantity'], label='Test', color='green')\n",
    "\n",
    "# Plot ARIMA forecast\n",
    "plt.plot(test.index, arima_forecast, label='ARIMA Forecast', color='blue')\n",
    "\n",
    "# Plot Exponential Smoothing forecast\n",
    "plt.plot(test.index, exp_smoothing_forecast, label='Exponential Smoothing Forecast', color='red')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('ARIMA vs Exponential Smoothing Forecast Comparison')\n",
    "plt.legend()\n",
    "plt.show();"
   ],
   "id": "bc9c067b75d6a89",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:10:41.561744Z",
     "start_time": "2024-07-29T19:10:41.493934Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "6b3849ee2f7fd5a5",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:43:16.800826Z",
     "start_time": "2024-07-29T14:43:16.785179Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f5c98f8731bf64c7",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:10:53.793824Z",
     "start_time": "2024-07-29T19:10:53.775632Z"
    }
   },
   "cell_type": "code",
   "source": "x = df.copy()",
   "id": "772211d5b2bad5d6",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:46:31.218783Z",
     "start_time": "2024-07-29T14:46:31.212602Z"
    }
   },
   "cell_type": "code",
   "source": "df = x.copy()",
   "id": "5667012220e99bdc",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:10:56.649985Z",
     "start_time": "2024-07-29T19:10:56.629303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import holidays\n",
    "# Function to create date features\n",
    "def create_date_features(data):\n",
    "    data[\"month\"] = data.index.month\n",
    "    data[\"day_of_month\"] = data.index.day\n",
    "    data[\"is_month_start\"] = data.index.is_month_start.astype(int)\n",
    "    data[\"is_month_end\"] = data.index.is_month_end.astype(int)\n",
    "    data[\"day_of_year\"] = data.index.dayofyear\n",
    "    data[\"week_of_year\"] = data.index.isocalendar().week\n",
    "    data[\"day_of_week\"] = data.index.dayofweek + 1\n",
    "    data[\"year\"] = data.index.year\n",
    "    data[\"is_weekend\"] = data.index.weekday\n",
    "    data['is_spring'] = data['month'].isin([3, 4, 5]).astype(int)\n",
    "    data['is_summer'] = data['month'].isin([6, 7, 8]).astype(int)\n",
    "    data['is_fall'] = data['month'].isin([9, 10, 11]).astype(int)\n",
    "    data['is_winter'] = data['month'].isin([12, 1, 2]).astype(int)\n",
    "    data['sin_day'] = np.sin(2 * np.pi * data.index.dayofweek / 7)\n",
    "    data['cos_day'] = np.cos(2 * np.pi * data.index.dayofweek / 7)\n",
    "    return data"
   ],
   "id": "6ac5bc49c84f8a3f",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:11:00.359998Z",
     "start_time": "2024-07-29T19:11:00.251117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Add holidays\n",
    " # Determine public holidays\n",
    "holiday = holidays.UK()\n",
    "df['is_public_holiday'] = df.index.map(lambda x: 1 if x in holiday else 0)\n",
    "def create_lag_and_window_features(data, target_col):\n",
    "    \"\"\"\n",
    "    Create lag and window features for a given DataFrame and target column.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input DataFrame.\n",
    "    target_col (str): The name of the target column to create features for.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with lag and window features.\n",
    "    \"\"\"\n",
    "    # Create lag features for the past week\n",
    "    for i in range(1, 8):\n",
    "        data[f'lag_{i}'] = data[target_col].shift(i)\n",
    "\n",
    "    # Rolling window statistics for 7 days\n",
    "    data['rolling_mean_7'] = data[target_col].rolling(window=7).mean()\n",
    "    data['rolling_sum_7'] = data[target_col].rolling(window=7).sum()\n",
    "    data['rolling_std_7'] = data[target_col].rolling(window=7).std()\n",
    "\n",
    "    # Rolling window statistics for 30 days\n",
    "    data['rolling_mean_30'] = data[target_col].rolling(window=30).mean()\n",
    "    data['rolling_sum_30'] = data[target_col].rolling(window=30).sum()\n",
    "    data['rolling_std_30'] = data[target_col].rolling(window=30).std()\n",
    "\n",
    "    # Expanding window statistics\n",
    "    data['expanding_sum'] = data[target_col].expanding().sum()\n",
    "\n",
    "    return data\n",
    "\n",
    "df = create_lag_and_window_features(df, 'quantity')\n",
    "df.head(5)"
   ],
   "id": "ccef881476c643a2",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:11:05.838938Z",
     "start_time": "2024-07-29T19:11:05.730888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill any remaining NaN values\n",
    "df = df.fillna(method='bfill')\n",
    "# Set winsorization threshold\n",
    "threshold = 60000\n",
    "\n",
    "# Winsorize the 'quantity' column\n",
    "df['quantity'] = df['quantity'].where(df['quantity'] <= threshold, threshold)\n",
    "df.head(5)"
   ],
   "id": "c6dd6421a92cf562",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:08:18.950378Z",
     "start_time": "2024-07-29T18:08:18.861203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import holidays\n",
    "# Function to create date features\n",
    "def create_date_features(data):\n",
    "    data[\"month\"] = data.index.month\n",
    "    data[\"day_of_month\"] = data.index.day\n",
    "    data[\"is_month_start\"] = data.index.is_month_start.astype(int)\n",
    "    data[\"is_month_end\"] = data.index.is_month_end.astype(int)\n",
    "    data[\"day_of_year\"] = data.index.dayofyear\n",
    "    data[\"week_of_year\"] = data.index.isocalendar().week\n",
    "    data[\"day_of_week\"] = data.index.dayofweek + 1\n",
    "    data[\"year\"] = data.index.year\n",
    "    data[\"is_weekend\"] = data.index.weekday\n",
    "    data['is_spring'] = data['month'].isin([3, 4, 5]).astype(int)\n",
    "    data['is_summer'] = data['month'].isin([6, 7, 8]).astype(int)\n",
    "    data['is_fall'] = data['month'].isin([9, 10, 11]).astype(int)\n",
    "    data['is_winter'] = data['month'].isin([12, 1, 2]).astype(int)\n",
    "    data['sin_day'] = np.sin(2 * np.pi * data.index.dayofweek / 7)\n",
    "    data['cos_day'] = np.cos(2 * np.pi * data.index.dayofweek / 7)\n",
    "    return data\n",
    "\n",
    "df = create_date_features(df)\n",
    " # Determine public holidays\n",
    "holiday = holidays.UK()\n",
    "df['is_public_holiday'] = df.index.map(lambda x: 1 if x in holiday else 0)\n",
    "def create_lag_and_window_features(data, target_col):\n",
    "    \"\"\"\n",
    "    Create lag and window features for a given DataFrame and target column.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input DataFrame.\n",
    "    target_col (str): The name of the target column to create features for.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with lag and window features.\n",
    "    \"\"\"\n",
    "    # Create lag features for the past week\n",
    "    for i in range(1, 8):\n",
    "        data[f'lag_{i}'] = data[target_col].shift(i)\n",
    "\n",
    "    # Rolling window statistics for 7 days\n",
    "    data['rolling_mean_7'] = data[target_col].rolling(window=7).mean()\n",
    "    data['rolling_sum_7'] = data[target_col].rolling(window=7).sum()\n",
    "    data['rolling_std_7'] = data[target_col].rolling(window=7).std()\n",
    "\n",
    "    # Rolling window statistics for 30 days\n",
    "    data['rolling_mean_30'] = data[target_col].rolling(window=30).mean()\n",
    "    data['rolling_sum_30'] = data[target_col].rolling(window=30).sum()\n",
    "    data['rolling_std_30'] = data[target_col].rolling(window=30).std()\n",
    "\n",
    "    # Expanding window statistics\n",
    "    data['expanding_sum'] = data[target_col].expanding().sum()\n",
    "\n",
    "    return data\n",
    "\n",
    "df = create_lag_and_window_features(df, 'quantity')\n",
    "\n",
    "\n",
    "# Fill any remaining NaN values\n",
    "df = df.fillna(method='bfill')\n",
    "\n",
    "# Set winsorization threshold\n",
    "threshold = 60000\n",
    "\n",
    "# Winsorize the 'quantity' column\n",
    "df['quantity'] = df['quantity'].where(df['quantity'] <= threshold, threshold)\n",
    "df.head(5)\n",
    "\n"
   ],
   "id": "161eb793d2466cbc",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:08:26.231263Z",
     "start_time": "2024-07-29T18:08:26.198943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "\n",
    "def create_date_features(data):\n",
    "    data[\"month\"] = data['ds'].dt.month\n",
    "    data[\"day_of_month\"] = data['ds'].dt.day\n",
    "    data[\"is_month_start\"] = data['ds'].dt.is_month_start.astype(int)\n",
    "    data[\"is_month_end\"] = data['ds'].dt.is_month_end.astype(int)\n",
    "    data[\"day_of_year\"] = data['ds'].dt.dayofyear\n",
    "    data[\"week_of_year\"] = data['ds'].dt.isocalendar().week\n",
    "    data[\"day_of_week\"] = data['ds'].dt.dayofweek + 1\n",
    "    data[\"year\"] = data['ds'].dt.year\n",
    "    data[\"is_weekend\"] = (data['ds'].dt.weekday >= 5).astype(int)\n",
    "    data['is_spring'] = data['month'].isin([3, 4, 5]).astype(int)\n",
    "    data['is_summer'] = data['month'].isin([6, 7, 8]).astype(int)\n",
    "    data['is_fall'] = data['month'].isin([9, 10, 11]).astype(int)\n",
    "    data['is_winter'] = data['month'].isin([12, 1, 2]).astype(int)\n",
    "    data['sin_day'] = np.sin(2 * np.pi * data['ds'].dt.dayofweek / 7)\n",
    "    data['cos_day'] = np.cos(2 * np.pi * data['ds'].dt.dayofweek / 7)\n",
    "    return data\n",
    "\n",
    "def create_lag_and_window_features(data, target_col):\n",
    "    for i in range(1, 8):\n",
    "        data[f'lag_{i}'] = data[target_col].shift(i)\n",
    "\n",
    "    data['rolling_mean_7'] = data[target_col].rolling(window=7).mean()\n",
    "    data['rolling_sum_7'] = data[target_col].rolling(window=7).sum()\n",
    "    data['rolling_std_7'] = data[target_col].rolling(window=7).std()\n",
    "\n",
    "    data['rolling_mean_30'] = data[target_col].rolling(window=30).mean()\n",
    "    data['rolling_sum_30'] = data[target_col].rolling(window=30).sum()\n",
    "    data['rolling_std_30'] = data[target_col].rolling(window=30).std()\n",
    "\n",
    "    data['expanding_sum'] = data[target_col].expanding().sum()\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure 'ds' column is datetime\n",
    "    df['ds'] = df.index\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "    # Create date features\n",
    "    df = create_date_features(df)\n",
    "\n",
    "    # Determine public holidays\n",
    "    holiday = holidays.UK()\n",
    "    df['is_public_holiday'] = df['ds'].apply(lambda x: 1 if x in holiday else 0)\n",
    "\n",
    "    # Create lag and window features\n",
    "    df = create_lag_and_window_features(df, 'quantity')\n",
    "\n",
    "    # Fill any remaining NaN values\n",
    "    df = df.fillna(method='bfill')\n",
    "\n",
    "    # Set winsorization threshold\n",
    "    threshold = 60000\n",
    "\n",
    "    # Winsorize the 'quantity' column\n",
    "    df['quantity'] = df['quantity'].where(df['quantity'] <= threshold, threshold)\n",
    "\n",
    "    return df"
   ],
   "id": "c3ae767d98a0bf09",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:09:07.791993Z",
     "start_time": "2024-07-29T18:09:07.667262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b = preprocess_data(df)\n",
    "b.head()"
   ],
   "id": "61560d3aa21b6981",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:12:54.507083Z",
     "start_time": "2024-07-29T19:11:53.716236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "# rml_data['ds'] = rml_data.index\n",
    "# rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "rml_data['y'] = rml_data['quantity']\n",
    "\n",
    "# Define features and target\n",
    "features = ['month', 'day_of_month', 'is_month_start', 'is_month_end',\n",
    "            'day_of_year', 'week_of_year', 'day_of_week', 'year',\n",
    "            'is_weekend', 'is_spring', 'is_summer', 'is_fall', 'is_winter',\n",
    "            'sin_day', 'cos_day', 'is_public_holiday', 'lag_1', 'lag_2', \n",
    "            'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean_7', \n",
    "            'rolling_sum_7', 'rolling_std_7', 'rolling_mean_30', \n",
    "            'rolling_sum_30', 'rolling_std_30', 'expanding_sum']\n",
    "\n",
    "target = 'y'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "# Define the models and hyperparameters for tuning\n",
    "models = {\n",
    "    'LightGBM': (lgb.LGBMRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'num_leaves': [31, 127]\n",
    "    }),\n",
    "    'XGBoost': (XGBRegressor(objective='reg:squarederror'), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 6]\n",
    "    }),\n",
    "    'RandomForest': (RandomForestRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'max_depth': [10, 20]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialize lists to store the scores\n",
    "mae_scores = {}\n",
    "mape_scores = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, (model, params) in models.items():\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    mae_scores[model_name] = mae\n",
    "    mape_scores[model_name] = mape\n",
    "    \n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, MAPE: {mape:.4%}\")\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name = min(mape_scores, key=mape_scores.get)\n",
    "best_model = models[best_model_name][0]\n",
    "print(f\"\\nThe best model is {best_model_name} with a MAPE of {mape_scores[best_model_name]:.4%}\")\n",
    "\n",
    "# Retrain the best model on the entire dataset\n",
    "best_model.fit(rml_data[features], rml_data[target])\n",
    "\n",
    "# Predict the next 30 days\n",
    "future_dates = pd.date_range(start=rml_data['ds'].max() + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "future_df = pd.DataFrame({\n",
    "    'ds': future_dates,\n",
    "    'month': future_dates.month,\n",
    "    'day_of_month': future_dates.day,\n",
    "    'is_month_start': future_dates.is_month_start.astype(int),\n",
    "    'is_month_end': future_dates.is_month_end.astype(int),\n",
    "    'day_of_year': future_dates.dayofyear,\n",
    "    'week_of_year': future_dates.isocalendar().week,\n",
    "    'day_of_week': future_dates.dayofweek + 1,\n",
    "    'year': future_dates.year,\n",
    "    'is_weekend': (future_dates.weekday >= 5).astype(int),\n",
    "    'is_spring': future_dates.month.isin([3, 4, 5]).astype(int),\n",
    "    'is_summer': future_dates.month.isin([6, 7, 8]).astype(int),\n",
    "    'is_fall': future_dates.month.isin([9, 10, 11]).astype(int),\n",
    "    'is_winter': future_dates.month.isin([12, 1, 2]).astype(int),\n",
    "    'sin_day': np.sin(2 * np.pi * future_dates.dayofweek / 7),\n",
    "    'cos_day': np.cos(2 * np.pi * future_dates.dayofweek / 7)\n",
    "})\n",
    "\n",
    "# Add public holidays for the future dates\n",
    "uk_holidays = holidays.UK()\n",
    "future_df['is_public_holiday'] = future_df['ds'].apply(lambda date: 1 if date in uk_holidays else 0)\n",
    "\n",
    "# Add lag features and rolling statistics for the future_df\n",
    "for lag in range(1, 8):\n",
    "    future_df[f'lag_{lag}'] = rml_data[target].shift(lag).iloc[-30:].values\n",
    "\n",
    "for window in [7, 30]:\n",
    "    future_df[f'rolling_mean_{window}'] = rml_data[target].rolling(window=window).mean().iloc[-30:].values\n",
    "    future_df[f'rolling_sum_{window}'] = rml_data[target].rolling(window=window).sum().iloc[-30:].values\n",
    "    future_df[f'rolling_std_{window}'] = rml_data[target].rolling(window=window).std().iloc[-30:].values\n",
    "\n",
    "future_df['expanding_sum'] = rml_data[target].expanding().sum().iloc[-30:].values\n",
    "\n",
    "# Predict future values using the best model\n",
    "future_predictions = best_model.predict(future_df[features])\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "plt.plot(future_df['ds'], future_predictions, label=f'Predicted - {best_model_name}', marker='x')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "22130f10b9311bf8",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:13:46.255777Z",
     "start_time": "2024-07-29T19:13:17.182711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "rml_data['y'] = rml_data['quantity']\n",
    "\n",
    "# Define features and target\n",
    "features = ['month', 'day_of_month', 'is_month_start', 'is_month_end',\n",
    "            'day_of_year', 'week_of_year', 'day_of_week', 'year',\n",
    "            'is_weekend', 'is_spring', 'is_summer', 'is_fall', 'is_winter',\n",
    "            'sin_day', 'cos_day', 'is_public_holiday', 'lag_1', 'lag_2', \n",
    "            'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean_7', \n",
    "            'rolling_sum_7', 'rolling_std_7', 'rolling_mean_30', \n",
    "            'rolling_sum_30', 'rolling_std_30', 'expanding_sum']\n",
    "\n",
    "target = 'y'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "# Define the models and hyperparameters for tuning\n",
    "models = {\n",
    "    'LightGBM': (lgb.LGBMRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'num_leaves': [31, 127]\n",
    "    }),\n",
    "    'XGBoost': (XGBRegressor(objective='reg:squarederror'), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 6]\n",
    "    }),\n",
    "    'RandomForest': (RandomForestRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'max_depth': [10, 20]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialize lists to store the scores\n",
    "mae_scores = {}\n",
    "mape_scores = {}\n",
    "best_params = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, (model, params) in models.items():\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    mae_scores[model_name] = mae\n",
    "    mape_scores[model_name] = mape\n",
    "    \n",
    "    print(f\"{model_name} - Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, MAPE: {mape:.4%}\")\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name = min(mape_scores, key=mape_scores.get)\n",
    "best_model = models[best_model_name][0]\n",
    "print(f\"\\nThe best model is {best_model_name} with a MAPE of {mape_scores[best_model_name]:.4%}\")\n",
    "print(f\"Best Hyperparameters: {best_params[best_model_name]}\")\n",
    "\n",
    "# Retrain the best model on the entire dataset\n",
    "best_model.set_params(**best_params[best_model_name])\n",
    "best_model.fit(rml_data[features], rml_data[target])\n",
    "\n",
    "# Predict the next 30 days\n",
    "future_dates = pd.date_range(start=rml_data['ds'].max() + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "future_df = pd.DataFrame({\n",
    "    'ds': future_dates,\n",
    "    'month': future_dates.month,\n",
    "    'day_of_month': future_dates.day,\n",
    "    'is_month_start': future_dates.is_month_start.astype(int),\n",
    "    'is_month_end': future_dates.is_month_end.astype(int),\n",
    "    'day_of_year': future_dates.dayofyear,\n",
    "    'week_of_year': future_dates.isocalendar().week,\n",
    "    'day_of_week': future_dates.dayofweek + 1,\n",
    "    'year': future_dates.year,\n",
    "    'is_weekend': (future_dates.weekday >= 5).astype(int),\n",
    "    'is_spring': future_dates.month.isin([3, 4, 5]).astype(int),\n",
    "    'is_summer': future_dates.month.isin([6, 7, 8]).astype(int),\n",
    "    'is_fall': future_dates.month.isin([9, 10, 11]).astype(int),\n",
    "    'is_winter': future_dates.month.isin([12, 1, 2]).astype(int),\n",
    "    'sin_day': np.sin(2 * np.pi * future_dates.dayofweek / 7),\n",
    "    'cos_day': np.cos(2 * np.pi * future_dates.dayofweek / 7)\n",
    "})\n",
    "\n",
    "# Add public holidays for the future dates\n",
    "uk_holidays = holidays.UK()\n",
    "future_df['is_public_holiday'] = future_df['ds'].apply(lambda date: 1 if date in uk_holidays else 0)\n",
    "\n",
    "# Add lag features and rolling statistics for the future_df\n",
    "for lag in range(1, 8):\n",
    "    future_df[f'lag_{lag}'] = rml_data[target].shift(lag).iloc[-30:].values\n",
    "\n",
    "for window in [7, 30]:\n",
    "    future_df[f'rolling_mean_{window}'] = rml_data[target].rolling(window=window).mean().iloc[-30:].values\n",
    "    future_df[f'rolling_sum_{window}'] = rml_data[target].rolling(window=window).sum().iloc[-30:].values\n",
    "    future_df[f'rolling_std_{window}'] = rml_data[target].rolling(window=window).std().iloc[-30:].values\n",
    "\n",
    "future_df['expanding_sum'] = rml_data[target].expanding().sum().iloc[-30:].values\n",
    "\n",
    "# Predict future values using the best model\n",
    "future_predictions = best_model.predict(future_df[features])\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(rml_data['ds'], rml_data['y'], label='Actual', marker='o')\n",
    "plt.plot(future_df['ds'], future_predictions, label=f'Predicted - {best_model_name}', marker='x')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "ef6c5b64bb63bd27",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:11:11.406271Z",
     "start_time": "2024-07-29T18:11:09.570376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "rml_data['y'] = rml_data['quantity']\n",
    "\n",
    "# Define features and target\n",
    "features = ['month', 'day_of_month', 'is_month_start', 'is_month_end',\n",
    "            'day_of_year', 'week_of_year', 'day_of_week', 'year',\n",
    "            'is_weekend', 'is_spring', 'is_summer', 'is_fall', 'is_winter',\n",
    "            'sin_day', 'cos_day', 'is_public_holiday', 'lag_1', 'lag_2', \n",
    "            'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean_7', \n",
    "            'rolling_sum_7', 'rolling_std_7', 'rolling_mean_30', \n",
    "            'rolling_sum_30', 'rolling_std_30', 'expanding_sum']\n",
    "\n",
    "target = 'y'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "# Define the best parameters for the XGBoost model\n",
    "best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "# Train the XGBoost model with the best parameters\n",
    "best_model = XGBRegressor(objective='reg:squarederror', **best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the entire historical period\n",
    "predictions = best_model.predict(rml_data[features])\n",
    "\n",
    "# Calculate MAPE for the predictions\n",
    "mape = mean_absolute_percentage_error(rml_data[target], predictions)\n",
    "print(f\"MAPE: {mape:.4%}\")\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot the actual values\n",
    "plt.plot(rml_data['ds'], rml_data['y'], label='Actual')\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(rml_data['ds'], predictions, label='Predicted')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n"
   ],
   "id": "5adec2b963eb7e11",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "87330f67b882ff0a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
