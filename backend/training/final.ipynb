{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sales Forecasting",
   "id": "aad580366681f93c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "5d5bbd69abe0ca54",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:04:40.008332Z",
     "start_time": "2024-07-29T20:04:39.996747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import the neccesary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gr\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tabulate import tabulate"
   ],
   "id": "c3c3171e473d2985",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:04:42.767730Z",
     "start_time": "2024-07-29T20:04:42.718445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"processed.csv\", parse_dates=['date'], index_col='date')\n",
    "df =df.asfreq('D')\n",
    "df =df[[\"quantity\"]]\n",
    "df.head()"
   ],
   "id": "2a77a6c1321dc22e",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:04:46.374463Z",
     "start_time": "2024-07-29T20:04:46.281996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "\n",
    "def create_date_features(data):\n",
    "    data[\"month\"] = data['ds'].dt.month\n",
    "    data[\"day_of_month\"] = data['ds'].dt.day\n",
    "    data[\"is_month_start\"] = data['ds'].dt.is_month_start.astype(int)\n",
    "    data[\"is_month_end\"] = data['ds'].dt.is_month_end.astype(int)\n",
    "    data[\"day_of_year\"] = data['ds'].dt.dayofyear\n",
    "    data[\"week_of_year\"] = data['ds'].dt.isocalendar().week\n",
    "    data[\"day_of_week\"] = data['ds'].dt.dayofweek + 1\n",
    "    data[\"year\"] = data['ds'].dt.year\n",
    "    data[\"is_weekend\"] = (data['ds'].dt.weekday >= 5).astype(int)\n",
    "    data['is_spring'] = data['month'].isin([3, 4, 5]).astype(int)\n",
    "    data['is_summer'] = data['month'].isin([6, 7, 8]).astype(int)\n",
    "    data['is_fall'] = data['month'].isin([9, 10, 11]).astype(int)\n",
    "    data['is_winter'] = data['month'].isin([12, 1, 2]).astype(int)\n",
    "    data['sin_day'] = np.sin(2 * np.pi * data['ds'].dt.dayofweek / 7)\n",
    "    data['cos_day'] = np.cos(2 * np.pi * data['ds'].dt.dayofweek / 7)\n",
    "    return data\n",
    "\n",
    "def create_lag_and_window_features(data, target_col):\n",
    "    for i in range(1, 8):\n",
    "        data[f'lag_{i}'] = data[target_col].shift(i)\n",
    "\n",
    "    data['rolling_mean_7'] = data[target_col].rolling(window=7).mean()\n",
    "    data['rolling_sum_7'] = data[target_col].rolling(window=7).sum()\n",
    "    data['rolling_std_7'] = data[target_col].rolling(window=7).std()\n",
    "\n",
    "    data['rolling_mean_30'] = data[target_col].rolling(window=30).mean()\n",
    "    data['rolling_sum_30'] = data[target_col].rolling(window=30).sum()\n",
    "    data['rolling_std_30'] = data[target_col].rolling(window=30).std()\n",
    "\n",
    "    data['expanding_sum'] = data[target_col].expanding().sum()\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure 'ds' column is datetime\n",
    "    df['ds'] = df.index\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "    # Create date features\n",
    "    df = create_date_features(df)\n",
    "\n",
    "    # Determine public holidays\n",
    "    holiday = holidays.UK()\n",
    "    df['is_public_holiday'] = df['ds'].apply(lambda x: 1 if x in holiday else 0)\n",
    "\n",
    "    # Create lag and window features\n",
    "    df = create_lag_and_window_features(df, 'quantity')\n",
    "\n",
    "    # Fill any remaining NaN values\n",
    "    df = df.fillna(method='bfill')\n",
    "\n",
    "    # Set winsorization threshold\n",
    "    threshold = 60000\n",
    "\n",
    "    # Winsorize the 'quantity' column\n",
    "    df['quantity'] = df['quantity'].where(df['quantity'] <= threshold, threshold)\n",
    "    df['y'] = df['quantity']\n",
    "\n",
    "    return df"
   ],
   "id": "9ab942ee1330c878",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:04:50.655002Z",
     "start_time": "2024-07-29T20:04:49.788331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b = preprocess_data(df)\n",
    "b.head()"
   ],
   "id": "c4f15c0d212e22c4",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ML",
   "id": "845cdbdb68f755b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "a75b30ce2e3415ff",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:05:05.021921Z",
     "start_time": "2024-07-29T20:04:57.364798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "features = ['month', 'day_of_month', 'is_month_start', 'is_month_end',\n",
    "            'day_of_year', 'week_of_year', 'day_of_week', 'year',\n",
    "            'is_weekend', 'is_spring', 'is_summer', 'is_fall', 'is_winter',\n",
    "            'sin_day', 'cos_day', 'is_public_holiday', 'lag_1', 'lag_2', \n",
    "            'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean_7', \n",
    "            'rolling_sum_7', 'rolling_std_7', 'rolling_mean_30', \n",
    "            'rolling_sum_30', 'rolling_std_30', 'expanding_sum']\n",
    "\n",
    "target = 'y'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-60]\n",
    "test_df = rml_data[-60:]\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, verbosity=-1),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, verbosity=0),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100)\n",
    "}\n",
    "\n",
    "# Initialize lists to store the scores\n",
    "mae_scores = {}\n",
    "mape_scores = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    mae_scores[model_name] = mae\n",
    "    mape_scores[model_name] = mape\n",
    "    \n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, MAPE: {mape:.4%}\")\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name = min(mape_scores, key=mape_scores.get)\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nThe best model is {best_model_name} with a MAPE of {mape_scores[best_model_name]:.4%}\")\n",
    "\n",
    "# Retrain the best model on the entire dataset\n",
    "best_model.fit(rml_data[features], rml_data[target])\n",
    "\n",
    "# Predict the next 60 days\n",
    "future_dates = pd.date_range(start=rml_data['ds'].max() + pd.Timedelta(days=1), periods=60, freq='D')\n",
    "future_df = pd.DataFrame({\n",
    "    'ds': future_dates,\n",
    "    'month': future_dates.month,\n",
    "    'day_of_month': future_dates.day,\n",
    "    'is_month_start': future_dates.is_month_start.astype(int),\n",
    "    'is_month_end': future_dates.is_month_end.astype(int),\n",
    "    'day_of_year': future_dates.dayofyear,\n",
    "    'week_of_year': future_dates.isocalendar().week,\n",
    "    'day_of_week': future_dates.dayofweek + 1,\n",
    "    'year': future_dates.year,\n",
    "    'is_weekend': (future_dates.weekday >= 5).astype(int),\n",
    "    'is_spring': future_dates.month.isin([3, 4, 5]).astype(int),\n",
    "    'is_summer': future_dates.month.isin([6, 7, 8]).astype(int),\n",
    "    'is_fall': future_dates.month.isin([9, 10, 11]).astype(int),\n",
    "    'is_winter': future_dates.month.isin([12, 1, 2]).astype(int),\n",
    "    'sin_day': np.sin(2 * np.pi * future_dates.dayofweek / 7),\n",
    "    'cos_day': np.cos(2 * np.pi * future_dates.dayofweek / 7)\n",
    "})\n",
    "\n",
    "# Add public holidays for the future dates\n",
    "uk_holidays = holidays.UK()\n",
    "future_df['is_public_holiday'] = future_df['ds'].apply(lambda date: 1 if date in uk_holidays else 0)\n",
    "\n",
    "# Add lag features and rolling statistics for the future_df\n",
    "for lag in range(1, 8):\n",
    "    future_df[f'lag_{lag}'] = rml_data[target].shift(lag).iloc[-60:].values\n",
    "\n",
    "for window in [7, 30]:\n",
    "    future_df[f'rolling_mean_{window}'] = rml_data[target].rolling(window=window).mean().iloc[-60:].values\n",
    "    future_df[f'rolling_sum_{window}'] = rml_data[target].rolling(window=window).sum().iloc[-60:].values\n",
    "    future_df[f'rolling_std_{window}'] = rml_data[target].rolling(window=window).std().iloc[-60:].values\n",
    "\n",
    "future_df['expanding_sum'] = rml_data[target].expanding().sum().iloc[-60:].values\n",
    "\n",
    "# Predict future values using the best model\n",
    "future_predictions = best_model.predict(future_df[features])\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "plt.plot(future_df['ds'], future_predictions, label=f'Predicted - {best_model_name}', marker='x')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "f36d543f3f958cae",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:05:23.215441Z",
     "start_time": "2024-07-29T20:05:18.091897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "features = ['month', 'day_of_month', 'is_month_start', 'is_month_end',\n",
    "            'day_of_year', 'week_of_year', 'day_of_week', 'year',\n",
    "            'is_weekend', 'is_spring', 'is_summer', 'is_fall', 'is_winter',\n",
    "            'sin_day', 'cos_day', 'is_public_holiday', 'lag_1', 'lag_2', \n",
    "            'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean_7', \n",
    "            'rolling_sum_7', 'rolling_std_7', 'rolling_mean_30', \n",
    "            'rolling_sum_30', 'rolling_std_30', 'expanding_sum']\n",
    "\n",
    "target = 'y'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, verbosity=-1),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, verbosity=0),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100)\n",
    "}\n",
    "\n",
    "# Initialize lists to store the scores\n",
    "mae_scores = {}\n",
    "mape_scores = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    mae_scores[model_name] = mae\n",
    "    mape_scores[model_name] = mape\n",
    "    \n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, MAPE: {mape:.4%}\")\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name = min(mape_scores, key=mape_scores.get)\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nThe best model is {best_model_name} with a MAPE of {mape_scores[best_model_name]:.4%}\")\n",
    "\n",
    "# Retrain the best model on the entire dataset\n",
    "best_model.fit(rml_data[features], rml_data[target])\n",
    "\n",
    "# Predict the next 30 days\n",
    "future_dates = pd.date_range(start=rml_data['ds'].max() + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "future_df = pd.DataFrame({\n",
    "    'ds': future_dates,\n",
    "    'month': future_dates.month,\n",
    "    'day_of_month': future_dates.day,\n",
    "    'is_month_start': future_dates.is_month_start.astype(int),\n",
    "    'is_month_end': future_dates.is_month_end.astype(int),\n",
    "    'day_of_year': future_dates.dayofyear,\n",
    "    'week_of_year': future_dates.isocalendar().week,\n",
    "    'day_of_week': future_dates.dayofweek + 1,\n",
    "    'year': future_dates.year,\n",
    "    'is_weekend': (future_dates.weekday >= 5).astype(int),\n",
    "    'is_spring': future_dates.month.isin([3, 4, 5]).astype(int),\n",
    "    'is_summer': future_dates.month.isin([6, 7, 8]).astype(int),\n",
    "    'is_fall': future_dates.month.isin([9, 10, 11]).astype(int),\n",
    "    'is_winter': future_dates.month.isin([12, 1, 2]).astype(int),\n",
    "    'sin_day': np.sin(2 * np.pi * future_dates.dayofweek / 7),\n",
    "    'cos_day': np.cos(2 * np.pi * future_dates.dayofweek / 7)\n",
    "})\n",
    "\n",
    "# Add public holidays for the future dates\n",
    "uk_holidays = holidays.UK()\n",
    "future_df['is_public_holiday'] = future_df['ds'].apply(lambda date: 1 if date in uk_holidays else 0)\n",
    "\n",
    "# Add lag features and rolling statistics for the future_df\n",
    "for lag in range(1, 8):\n",
    "    future_df[f'lag_{lag}'] = rml_data[target].shift(lag).iloc[-30:].values\n",
    "\n",
    "for window in [7, 30]:\n",
    "    future_df[f'rolling_mean_{window}'] = rml_data[target].rolling(window=window).mean().iloc[-30:].values\n",
    "    future_df[f'rolling_sum_{window}'] = rml_data[target].rolling(window=window).sum().iloc[-30:].values\n",
    "    future_df[f'rolling_std_{window}'] = rml_data[target].rolling(window=window).std().iloc[-30:].values\n",
    "\n",
    "future_df['expanding_sum'] = rml_data[target].expanding().sum().iloc[-30:].values\n",
    "\n",
    "# Predict future values using the best model\n",
    "future_predictions = best_model.predict(future_df[features])\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "plt.plot(future_df['ds'], future_predictions, label=f'Predicted - {best_model_name}', marker='x')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "c82393fa759baed9",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:06:15.901118Z",
     "start_time": "2024-07-29T20:05:33.813545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "\n",
    "# Define features and target\n",
    "features = ['month', 'day_of_month', 'is_month_start', 'is_month_end',\n",
    "            'day_of_year', 'week_of_year', 'day_of_week', 'year',\n",
    "            'is_weekend', 'is_spring', 'is_summer', 'is_fall', 'is_winter',\n",
    "            'sin_day', 'cos_day', 'is_public_holiday', 'lag_1', 'lag_2', \n",
    "            'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean_7', \n",
    "            'rolling_sum_7', 'rolling_std_7', 'rolling_mean_30', \n",
    "            'rolling_sum_30', 'rolling_std_30', 'expanding_sum']\n",
    "\n",
    "target = 'y'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "# Define the models and hyperparameters for tuning\n",
    "models = {\n",
    "    'LightGBM': (lgb.LGBMRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'num_leaves': [31, 127]\n",
    "    }),\n",
    "    'XGBoost': (XGBRegressor(objective='reg:squarederror'), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 6]\n",
    "    }),\n",
    "    'RandomForest': (RandomForestRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'max_depth': [10, 20]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialize lists to store the scores\n",
    "mae_scores = {}\n",
    "mape_scores = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, (model, params) in models.items():\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    mae_scores[model_name] = mae\n",
    "    mape_scores[model_name] = mape\n",
    "    \n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, MAPE: {mape:.4%}\")\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name = min(mape_scores, key=mape_scores.get)\n",
    "best_model = models[best_model_name][0]\n",
    "print(f\"\\nThe best model is {best_model_name} with a MAPE of {mape_scores[best_model_name]:.4%}\")\n",
    "\n",
    "# Retrain the best model on the entire dataset\n",
    "best_model.fit(rml_data[features], rml_data[target])\n",
    "\n",
    "# Predict the next 30 days\n",
    "future_dates = pd.date_range(start=rml_data['ds'].max() + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "future_df = pd.DataFrame({\n",
    "    'ds': future_dates,\n",
    "    'month': future_dates.month,\n",
    "    'day_of_month': future_dates.day,\n",
    "    'is_month_start': future_dates.is_month_start.astype(int),\n",
    "    'is_month_end': future_dates.is_month_end.astype(int),\n",
    "    'day_of_year': future_dates.dayofyear,\n",
    "    'week_of_year': future_dates.isocalendar().week,\n",
    "    'day_of_week': future_dates.dayofweek + 1,\n",
    "    'year': future_dates.year,\n",
    "    'is_weekend': (future_dates.weekday >= 5).astype(int),\n",
    "    'is_spring': future_dates.month.isin([3, 4, 5]).astype(int),\n",
    "    'is_summer': future_dates.month.isin([6, 7, 8]).astype(int),\n",
    "    'is_fall': future_dates.month.isin([9, 10, 11]).astype(int),\n",
    "    'is_winter': future_dates.month.isin([12, 1, 2]).astype(int),\n",
    "    'sin_day': np.sin(2 * np.pi * future_dates.dayofweek / 7),\n",
    "    'cos_day': np.cos(2 * np.pi * future_dates.dayofweek / 7)\n",
    "})\n",
    "\n",
    "# Add public holidays for the future dates\n",
    "uk_holidays = holidays.UK()\n",
    "future_df['is_public_holiday'] = future_df['ds'].apply(lambda date: 1 if date in uk_holidays else 0)\n",
    "\n",
    "# Add lag features and rolling statistics for the future_df\n",
    "for lag in range(1, 8):\n",
    "    future_df[f'lag_{lag}'] = rml_data[target].shift(lag).iloc[-30:].values\n",
    "\n",
    "for window in [7, 30]:\n",
    "    future_df[f'rolling_mean_{window}'] = rml_data[target].rolling(window=window).mean().iloc[-30:].values\n",
    "    future_df[f'rolling_sum_{window}'] = rml_data[target].rolling(window=window).sum().iloc[-30:].values\n",
    "    future_df[f'rolling_std_{window}'] = rml_data[target].rolling(window=window).std().iloc[-30:].values\n",
    "\n",
    "future_df['expanding_sum'] = rml_data[target].expanding().sum().iloc[-30:].values\n",
    "\n",
    "# Predict future values using the best model\n",
    "future_predictions = best_model.predict(future_df[features])\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "plt.plot(future_df['ds'], future_predictions, label=f'Predicted - {best_model_name}', marker='x')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "ef98bad855ff884d",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:38:47.048584Z",
     "start_time": "2024-07-29T20:38:06.670144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "\n",
    "# Define features and target\n",
    "features = ['month', 'day_of_month', 'is_month_start', 'is_month_end',\n",
    "            'day_of_year', 'week_of_year', 'day_of_week', 'year',\n",
    "            'is_weekend', 'is_spring', 'is_summer', 'is_fall', 'is_winter',\n",
    "            'sin_day', 'cos_day', 'is_public_holiday', 'lag_1', 'lag_2', \n",
    "            'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean_7', \n",
    "            'rolling_sum_7', 'rolling_std_7', 'rolling_mean_30', \n",
    "            'rolling_sum_30', 'rolling_std_30', 'expanding_sum']\n",
    "\n",
    "target = 'y'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "# Define the models and hyperparameters for tuning\n",
    "models = {\n",
    "    'LightGBM': (lgb.LGBMRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'num_leaves': [31, 127]\n",
    "    }),\n",
    "    'XGBoost': (XGBRegressor(objective='reg:squarederror'), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 6]\n",
    "    }),\n",
    "    'RandomForest': (RandomForestRegressor(), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'max_depth': [10, 20]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialize lists to store the scores\n",
    "mae_scores = {}\n",
    "mape_scores = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, (model, params) in models.items():\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    mae_scores[model_name] = mae\n",
    "    mape_scores[model_name] = mape\n",
    "    \n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, MAPE: {mape:.4%}\")\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name = min(mape_scores, key=mape_scores.get)\n",
    "best_model = models[best_model_name][0]\n",
    "print(f\"\\nThe best model is {best_model_name} with a MAPE of {mape_scores[best_model_name]:.4%}\")\n",
    "\n",
    "# Retrain the best model on the entire dataset\n",
    "best_model.fit(rml_data[features], rml_data[target])\n",
    "\n",
    "# Predict the next 30 days\n",
    "future_dates = pd.date_range(start=rml_data['ds'].max() + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "future_df = pd.DataFrame({\n",
    "    'ds': future_dates,\n",
    "    'month': future_dates.month,\n",
    "    'day_of_month': future_dates.day,\n",
    "    'is_month_start': future_dates.is_month_start.astype(int),\n",
    "    'is_month_end': future_dates.is_month_end.astype(int),\n",
    "    'day_of_year': future_dates.dayofyear,\n",
    "    'week_of_year': future_dates.isocalendar().week,\n",
    "    'day_of_week': future_dates.dayofweek + 1,\n",
    "    'year': future_dates.year,\n",
    "    'is_weekend': (future_dates.weekday >= 5).astype(int),\n",
    "    'is_spring': future_dates.month.isin([3, 4, 5]).astype(int),\n",
    "    'is_summer': future_dates.month.isin([6, 7, 8]).astype(int),\n",
    "    'is_fall': future_dates.month.isin([9, 10, 11]).astype(int),\n",
    "    'is_winter': future_dates.month.isin([12, 1, 2]).astype(int),\n",
    "    'sin_day': np.sin(2 * np.pi * future_dates.dayofweek / 7),\n",
    "    'cos_day': np.cos(2 * np.pi * future_dates.dayofweek / 7)\n",
    "})\n",
    "\n",
    "# Add public holidays for the future dates\n",
    "uk_holidays = holidays.UK()\n",
    "future_df['is_public_holiday'] = future_df['ds'].apply(lambda date: 1 if date in uk_holidays else 0)\n",
    "\n",
    "# Add lag features and rolling statistics for the future_df\n",
    "for lag in range(1, 8):\n",
    "    future_df[f'lag_{lag}'] = rml_data[target].shift(lag).iloc[-30:].values\n",
    "\n",
    "for window in [7, 30]:\n",
    "    future_df[f'rolling_mean_{window}'] = rml_data[target].rolling(window=window).mean().iloc[-30:].values\n",
    "    future_df[f'rolling_sum_{window}'] = rml_data[target].rolling(window=window).sum().iloc[-30:].values\n",
    "    future_df[f'rolling_std_{window}'] = rml_data[target].rolling(window=window).std().iloc[-30:].values\n",
    "\n",
    "future_df['expanding_sum'] = rml_data[target].expanding().sum().iloc[-30:].values\n",
    "\n",
    "# Predict future values using the best model\n",
    "future_predictions = best_model.predict(future_df[features])\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "plt.plot(future_df['ds'], future_predictions, label=f'Predicted - {best_model_name}', marker='x')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "a434bc36b52a82c0",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:21:13.922611Z",
     "start_time": "2024-07-29T17:16:35.806059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS, NBEATS, LSTM\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "\n",
    "# Add a unique_id column\n",
    "rml_data['unique_id'] = 'series_1'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-60]\n",
    "test_df = rml_data[-60:]\n",
    "\n",
    "# Define the models and their respective parameters\n",
    "nhits_params = {\n",
    "    'h': 60,\n",
    "    'input_size': 30,\n",
    "    'max_steps': 50\n",
    "}\n",
    "\n",
    "nbeats_params = {\n",
    "    'h': 60,\n",
    "    'input_size': 30,\n",
    "    'max_steps': 50\n",
    "}\n",
    "\n",
    "lstm_params = {\n",
    "    'h': 60,\n",
    "    'input_size': 30,\n",
    "    'max_steps': 50\n",
    "}\n",
    "\n",
    "# Initialize the models\n",
    "nhits_model = NHITS(**nhits_params)\n",
    "nbeats_model = NBEATS(**nbeats_params)\n",
    "lstm_model = LSTM(**lstm_params)\n",
    "\n",
    "# Train each model on the training data and evaluate on test data\n",
    "models = [nhits_model, nbeats_model, lstm_model]\n",
    "model_names = ['NHITS', 'NBEATS', 'LSTM']\n",
    "mape_scores = []\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    nf = NeuralForecast(models=[model], freq='D')\n",
    "    nf.fit(df=train_df, id_col='unique_id', time_col='ds', target_col='y')\n",
    "    forecasts = nf.predict(futr_df=test_df)\n",
    "    print(forecasts.head())\n",
    "    mape = mean_absolute_percentage_error(test_df['y'], forecasts[name])\n",
    "    mape_scores.append((name, mape))\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name, best_mape = min(mape_scores, key=lambda x: x[1])\n",
    "best_model = None\n",
    "\n",
    "if best_model_name == 'NHITS':\n",
    "    best_model = NHITS(**nhits_params)\n",
    "elif best_model_name == 'NBEATS':\n",
    "    best_model = NBEATS(**nbeats_params)\n",
    "elif best_model_name == 'LSTM':\n",
    "    best_model = LSTM(**lstm_params)\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "nf_best_model = NeuralForecast(models=[best_model], freq='D')\n",
    "nf_best_model.fit(df=rml_data, id_col='unique_id', time_col='ds', target_col='y')\n",
    "\n",
    "# Predict the next 60 days with the best model\n",
    "future_dates = pd.date_range(rml_data['ds'].max() + pd.Timedelta(days=1), periods=60, freq='D')\n",
    "future_df = pd.DataFrame({'ds': future_dates})\n",
    "future_df['unique_id'] = 'series_1'\n",
    "\n",
    "final_forecasts = nf_best_model.predict(futr_df=future_df)\n",
    "\n",
    "# Plot actual vs predicted values for the best model\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot the test data\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "\n",
    "# Plot the forecasts\n",
    "plt.plot(\n",
    "    future_dates,\n",
    "    final_forecasts[best_model_name][:60],  # Ensure we take only 60 predictions\n",
    "    label=f'Predicted - {best_model_name}',\n",
    "    marker='x',\n",
    ")\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'Actual vs Predicted Values using {best_model_name}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"The best model is {best_model_name} with a MAPE of {best_mape}\")\n"
   ],
   "id": "a28c5d262d5c9b2d",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:23:45.658424Z",
     "start_time": "2024-07-29T17:21:13.922611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS, NBEATS, LSTM\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "\n",
    "# Add a unique_id column\n",
    "rml_data['unique_id'] = 'series_1'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "# Define the models and their respective parameters\n",
    "nhits_params = {\n",
    "    'h': 30,\n",
    "    'input_size': 30,\n",
    "    'max_steps': 50\n",
    "}\n",
    "\n",
    "nbeats_params = {\n",
    "    'h': 30,\n",
    "    'input_size': 30,\n",
    "    'max_steps': 50\n",
    "}\n",
    "\n",
    "lstm_params = {\n",
    "    'h': 30,\n",
    "    'input_size': 30,\n",
    "    'max_steps': 50\n",
    "}\n",
    "\n",
    "# Initialize the models\n",
    "nhits_model = NHITS(**nhits_params)\n",
    "nbeats_model = NBEATS(**nbeats_params)\n",
    "lstm_model = LSTM(**lstm_params)\n",
    "\n",
    "# Train each model on the training data and evaluate on test data\n",
    "models = [nhits_model, nbeats_model, lstm_model]\n",
    "model_names = ['NHITS', 'NBEATS', 'LSTM']\n",
    "mape_scores = []\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    nf = NeuralForecast(models=[model], freq='D')\n",
    "    nf.fit(df=train_df, id_col='unique_id', time_col='ds', target_col='y')\n",
    "    forecasts = nf.predict(futr_df=test_df)\n",
    "    print(forecasts.head())\n",
    "    mape = mean_absolute_percentage_error(test_df['y'], forecasts[name])\n",
    "    mape_scores.append((name, mape))\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name, best_mape = min(mape_scores, key=lambda x: x[1])\n",
    "best_model = None\n",
    "\n",
    "if best_model_name == 'NHITS':\n",
    "    best_model = NHITS(**nhits_params)\n",
    "elif best_model_name == 'NBEATS':\n",
    "    best_model = NBEATS(**nbeats_params)\n",
    "elif best_model_name == 'LSTM':\n",
    "    best_model = LSTM(**lstm_params)\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "nf_best_model = NeuralForecast(models=[best_model], freq='D')\n",
    "nf_best_model.fit(df=rml_data, id_col='unique_id', time_col='ds', target_col='y')\n",
    "\n",
    "# Predict the next 30 days with the best model\n",
    "future_dates = pd.date_range(rml_data['ds'].max() + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "future_df = pd.DataFrame({'ds': future_dates})\n",
    "future_df['unique_id'] = 'series_1'\n",
    "\n",
    "final_forecasts = nf_best_model.predict(futr_df=future_df)\n",
    "\n",
    "# Plot actual vs predicted values for the best model\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot the test data\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "\n",
    "# Plot the forecasts\n",
    "plt.plot(\n",
    "    future_dates,\n",
    "    final_forecasts[best_model_name][:30],  # Ensure we take only 30 predictions\n",
    "    label=f'Predicted - {best_model_name}',\n",
    "    marker='x',\n",
    ")\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'Actual vs Predicted Values using {best_model_name}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"The best model is {best_model_name} with a MAPE of {best_mape}\")\n"
   ],
   "id": "7460f317379672ee",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:49:18.389488Z",
     "start_time": "2024-07-29T17:23:45.658424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS, NBEATS, LSTM\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "rml_data = b.copy()\n",
    "\n",
    "# Ensure 'ds' column is datetime\n",
    "rml_data['ds'] = pd.to_datetime(rml_data['ds'])\n",
    "\n",
    "# Add a unique_id column\n",
    "rml_data['unique_id'] = 'series_1'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = rml_data[:-30]\n",
    "test_df = rml_data[-30:]\n",
    "\n",
    "# Define the parameter grids for each model\n",
    "nhits_param_grid = {\n",
    "    'h': [30],\n",
    "    'input_size': [30, 60, 90],\n",
    "    'max_steps': [50, 100, 150]\n",
    "}\n",
    "\n",
    "nbeats_param_grid = {\n",
    "    'h': [30],\n",
    "    'input_size': [30, 60, 90],\n",
    "    'max_steps': [50, 100, 150]\n",
    "}\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'h': [30],\n",
    "    'input_size': [30, 60, 90],\n",
    "    'max_steps': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# Initialize the parameter grids\n",
    "nhits_params_list = list(ParameterGrid(nhits_param_grid))\n",
    "nbeats_params_list = list(ParameterGrid(nbeats_param_grid))\n",
    "lstm_params_list = list(ParameterGrid(lstm_param_grid))\n",
    "\n",
    "# Function to train and evaluate a model with given parameters\n",
    "def train_evaluate_model(model_class, param_list, train_df, test_df, model_name):\n",
    "    best_params = None\n",
    "    best_mape = float('inf')\n",
    "    best_forecasts = None\n",
    "\n",
    "    for params in param_list:\n",
    "        model = model_class(**params)\n",
    "        nf = NeuralForecast(models=[model], freq='D')\n",
    "        nf.fit(df=train_df, id_col='unique_id', time_col='ds', target_col='y')\n",
    "        forecasts = nf.predict(futr_df=test_df)\n",
    "        \n",
    "        mape = mean_absolute_percentage_error(test_df['y'], forecasts[model_name])\n",
    "        \n",
    "        if mape < best_mape:\n",
    "            best_mape = mape\n",
    "            best_params = params\n",
    "            best_forecasts = forecasts\n",
    "    \n",
    "    return best_params, best_mape, best_forecasts\n",
    "\n",
    "# Fine-tune and evaluate each model\n",
    "nhits_best_params, nhits_best_mape, nhits_best_forecasts = train_evaluate_model(\n",
    "    NHITS, nhits_params_list, train_df, test_df, 'NHITS'\n",
    ")\n",
    "\n",
    "nbeats_best_params, nbeats_best_mape, nbeats_best_forecasts = train_evaluate_model(\n",
    "    NBEATS, nbeats_params_list, train_df, test_df, 'NBEATS'\n",
    ")\n",
    "\n",
    "lstm_best_params, lstm_best_mape, lstm_best_forecasts = train_evaluate_model(\n",
    "    LSTM, lstm_params_list, train_df, test_df, 'LSTM'\n",
    ")\n",
    "\n",
    "# Store the best models and their MAPE scores\n",
    "best_models = [\n",
    "    ('NHITS', nhits_best_mape, NHITS, nhits_best_params, nhits_best_forecasts),\n",
    "    ('NBEATS', nbeats_best_mape, NBEATS, nbeats_best_params, nbeats_best_forecasts),\n",
    "    ('LSTM', lstm_best_mape, LSTM, lstm_best_params, lstm_best_forecasts)\n",
    "]\n",
    "\n",
    "# Select the best model based on MAPE\n",
    "best_model_name, best_mape, best_model_class, best_model_params, best_forecasts = min(\n",
    "    best_models, key=lambda x: x[1]\n",
    ")\n",
    "\n",
    "# Train the best model on the entire dataset with the best parameters\n",
    "best_model = best_model_class(**best_model_params)\n",
    "nf_best_model = NeuralForecast(models=[best_model], freq='D')\n",
    "nf_best_model.fit(df=rml_data, id_col='unique_id', time_col='ds', target_col='y')\n",
    "\n",
    "# Predict the next 30 days with the best model\n",
    "future_dates = pd.date_range(rml_data['ds'].max() + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "future_df = pd.DataFrame({'ds': future_dates})\n",
    "future_df['unique_id'] = 'series_1'\n",
    "\n",
    "final_forecasts = nf_best_model.predict(futr_df=future_df)\n",
    "\n",
    "# Plot actual vs predicted values for the best model\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot the test data\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', marker='o')\n",
    "\n",
    "# Plot the forecasts\n",
    "plt.plot(\n",
    "    future_dates,\n",
    "    final_forecasts[best_model_name][:30],  # Ensure we take only 30 predictions\n",
    "    label=f'Predicted - {best_model_name}',\n",
    "    marker='x',\n",
    ")\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'Actual vs Predicted Values using {best_model_name}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"The best model is {best_model_name} with a MAPE of {best_mape}\")\n",
    "print(f\"Best parameters: {best_model_params}\")\n"
   ],
   "id": "9cc985619f3cde64",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "defdfbc1d74c587c",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
