{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simulating main functions for different manipulations of customer and sales data",
   "id": "93d5ce6645e1b217"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gr"
   ],
   "id": "39eb76f5f29f5d78"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "master_df = pd.read_csv(\"express.csv\")\n",
    "master_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:49:15.796095700Z",
     "start_time": "2024-05-23T23:49:08.506435200Z"
    }
   },
   "id": "f4d0cb78a413de3a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Remove Credit/Cancelled transactions\n",
    "master_df = master_df[master_df[\"OnCredit\"]==False]\n",
    "master_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:09:05.968734800Z",
     "start_time": "2024-05-07T13:09:05.361074900Z"
    }
   },
   "id": "fcf4277531a84533",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forecast Simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf12a197b2f4cf61"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Select Relevant Columns\n",
    "forecast = master_df[[\"InvoiceDate\",\"CustomerID\",\"InvoiceNo\",\"StockCode\",\"Quantity\",\"TotalPrice\"]]\n",
    "forecast"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:09:38.580174500Z",
     "start_time": "2024-05-07T13:09:24.676906100Z"
    }
   },
   "id": "899ceb071b20e05e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Convert date to datetime\n",
    "forecast[\"InvoiceDate\"] = pd.to_datetime(forecast[\"InvoiceDate\"])\n",
    "forecast[\"InvoiceDate\"].dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:09:59.982022400Z",
     "start_time": "2024-05-07T13:09:25.635092500Z"
    }
   },
   "id": "df103626f9c1a100",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "forecast[\"Date\"] = pd.to_datetime(forecast[\"InvoiceDate\"])\n",
    "forecast[\"Date\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:10:00.230450700Z",
     "start_time": "2024-05-07T13:09:59.454386Z"
    }
   },
   "id": "f5b746a0298fc348",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "daily_sales = forecast.groupby(['InvoiceDate', 'StockCode'])['Quantity',\"TotalPrice\"].sum().reset_index()\n",
    "daily_sales\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:10:05.349329400Z",
     "start_time": "2024-05-07T13:10:00.229447Z"
    }
   },
   "id": "b9ef4401b94d9de0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "daily_sales[\"Day\"] = daily_sales[\"InvoiceDate\"].dt.day\n",
    "daily_sales[\"Month\"] = daily_sales[\"InvoiceDate\"].dt.month\n",
    "daily_sales[\"Year\"] = daily_sales[\"InvoiceDate\"].dt.year\n",
    "daily_sales[\"InvoiceDate\"] = daily_sales[\"InvoiceDate\"].dt.date\n",
    "daily_sales"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:10:05.352329400Z",
     "start_time": "2024-05-07T13:10:03.672990900Z"
    }
   },
   "id": "322b90721859bcd4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Set date as index\n",
    "nd =daily_sales.set_index(\"InvoiceDate\")\n",
    "nd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:40.049159600Z",
     "start_time": "2024-03-11T14:24:39.835286900Z"
    }
   },
   "id": "349393df64008dd3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#We can use this if we consider demand forecasting for individual products\n",
    "# Group sales for each product per month\n",
    "# monthly_sales = nd.groupby('StockCode').resample('M')['Quantity'].sum().reset_index()\n",
    "# monthly_sales"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:40.106048200Z",
     "start_time": "2024-03-11T14:24:39.966518300Z"
    }
   },
   "id": "9336d9546d003aca",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Calculate total sales of everything per day\n",
    "daily_sales"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:40.532951800Z",
     "start_time": "2024-03-11T14:24:39.986212400Z"
    }
   },
   "id": "6cabd2fd9cfdb7d1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Find the total sales daily\n",
    "total_daily = daily_sales.groupby(\"InvoiceDate\")[\"Quantity\"].sum().reset_index()\n",
    "total_daily"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:10:19.441898400Z",
     "start_time": "2024-05-07T13:10:17.779512500Z"
    }
   },
   "id": "837d3089b0c46093",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "total_daily[\"InvoiceDate\"] = pd.to_datetime(total_daily[\"InvoiceDate\"])\n",
    "total_daily.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:10:19.743444400Z",
     "start_time": "2024-05-07T13:10:19.172548700Z"
    }
   },
   "id": "140aad7ceab3d751",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Chooose January 2011\n",
    "jan_sales =  total_daily[(total_daily[\"InvoiceDate\"].dt.month) == 1 & (total_daily[\"InvoiceDate\"].dt.year == 2011)]\n",
    "jan_sales"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:10:32.508989300Z",
     "start_time": "2024-05-07T13:10:32.257686200Z"
    }
   },
   "id": "d0516a8fc266d0a1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "jan_sales.to_csv(\"sample_sales_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:11:47.103436500Z",
     "start_time": "2024-05-07T13:11:46.960652600Z"
    }
   },
   "id": "3db537670ce66272",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Plot total sales for each day in January of the specified year\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(jan_sales['InvoiceDate'], jan_sales['Quantity'], marker='o', linestyle='-')\n",
    "plt.title(f'Total Sales for January 2011')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:42.243906800Z",
     "start_time": "2024-03-11T14:24:40.269546600Z"
    }
   },
   "id": "ff4b60e6ef3da6a5",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Peak/ Tull Marking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d082f15f22d0f0c9"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# (Optional) Dummy data generation for testing purposes\n",
    "import datetime\n",
    "\n",
    "def generate_dummy_data(start_date='2024-03-01', end_date='2024-03-31'):\n",
    "  \"\"\"Generates dummy sales data with random fluctuations, peaks, and dips.\"\"\"\n",
    "  dates = pd.date_range(start=start_date, end=end_date)\n",
    "  base_sales = np.random.randint(50, 150, size=len(dates))\n",
    "  for i in random.sample(range(len(dates)), k=5):\n",
    "      base_sales[i] *= random.uniform(1.5, 2)  # Introduce random peaks\n",
    "  for i in random.sample(range(len(dates)), k=5):\n",
    "      base_sales[i] *= random.uniform(0.5, 0.8)  # Introduce random dips\n",
    "  return pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:42.251499400Z",
     "start_time": "2024-03-11T14:24:42.087816300Z"
    }
   },
   "id": "2661a4f64c8f09a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def proximity_calculator(days):\n",
    "    \"\"\"Groups closely spaced dates into promotional periods.\n",
    "\n",
    "    Args:\n",
    "        days (list): A list of 'Timestamp' objects.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists, where each sub-list represents a promotional period (containing 'Timestamp' objects).\n",
    "    \"\"\"\n",
    "    # Sort the list of days\n",
    "    days.sort()\n",
    "\n",
    "    # List to store the resulting periods\n",
    "    periods = []\n",
    "\n",
    "    # Iterate through the sorted days\n",
    "    i = 0\n",
    "    while i < len(days):\n",
    "        # Initialize the start and end dates for the current period\n",
    "        start_date = days[i]\n",
    "        end_date = days[i]\n",
    "\n",
    "        # Find the end date of the current period\n",
    "        while i + 1 < len(days) and (days[i + 1] - end_date).days <= 3:\n",
    "            end_date = days[i + 1]\n",
    "            i += 1\n",
    "\n",
    "        # Add the current period to the list of periods\n",
    "        periods.append(pd.date_range(start=start_date, end=end_date, freq='D').tolist())\n",
    "\n",
    "        # Move to the next date\n",
    "        i += 1\n",
    "\n",
    "    return periods\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:43.060504200Z",
     "start_time": "2024-03-11T14:24:42.122129800Z"
    }
   },
   "id": "5f4fce393847791a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def find_promo_days(sales_data, peak_threshold=1.2, lull_threshold=0.5, num_promos=3, proximity_days=3):\n",
    "    \"\"\"Identifies peak and lull promotional periods based on percentage thresholds of average sales volume, \n",
    "    considering proximity to group close dates into extended periods.\n",
    "\n",
    "    Args:\n",
    "        sales_data (pd.DataFrame): DataFrame containing 'Date' and 'Sales Volume' columns.\n",
    "        peak_threshold (float, optional): Multiplier for avg. sales volume to define a peak. Defaults to 1.2 (20% above average).\n",
    "        lull_threshold (float, optional): Multiplier for avg. sales volume to define a lull. Defaults to 0.8 (20% below average).\n",
    "        num_promos (int, optional): The maximum number of promotions per month (ignored in this implementation). Defaults to 3.\n",
    "        proximity_days (int, optional): The maximum number of days between dates to consider them part of the same promotional period. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing lists of peak and lull sales dates.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(sales_data, pd.DataFrame):\n",
    "        raise TypeError(\"sales_data must be a pandas DataFrame\")\n",
    "\n",
    "    # Calculate average sales volume\n",
    "    avg_sales = sales_data['Quantity'].mean()\n",
    "\n",
    "    # Apply thresholds to identify days within peak or lull zones\n",
    "    peak_condition = sales_data['Quantity'] >= avg_sales * peak_threshold\n",
    "    lull_condition = sales_data['Quantity'] <= avg_sales * lull_threshold\n",
    "\n",
    "    # Get top peaks and lulls based on the conditions\n",
    "    peak_days = sales_data[peak_condition].nlargest(num_promos, 'Quantity')['InvoiceDate'].tolist()\n",
    "    lull_days = sales_data[lull_condition].nsmallest(num_promos, 'Quantity')['InvoiceDate'].tolist()\n",
    "\n",
    "    # Group peak and lull days into promotional periods based on proximity using proximity_calculator\n",
    "    peak_periods = proximity_calculator(peak_days)\n",
    "    lull_periods = proximity_calculator(lull_days)\n",
    "\n",
    "    return peak_periods, lull_periods\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:43.060504200Z",
     "start_time": "2024-03-11T14:24:42.678754600Z"
    }
   },
   "id": "e0e1f84211e1e282",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "peak ,tull = find_promo_days(jan_sales, proximity_days=3) \n",
    "tull\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:43.060504200Z",
     "start_time": "2024-03-11T14:24:42.832613500Z"
    }
   },
   "id": "6686c5d8af106e8b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "peak"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:43.422233800Z",
     "start_time": "2024-03-11T14:24:42.965717800Z"
    }
   },
   "id": "495d3bb32c25cd6b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_promo_days(sales_data, peak_threshold=1.2, lull_threshold=0.5, num_promos=3, proximity_days=3):\n",
    "    \"\"\"Identifies peak and lull promotional periods based on percentage thresholds of average sales volume, \n",
    "    considering proximity to group close dates into extended periods.\n",
    "\n",
    "    Args:\n",
    "        sales_data (pd.DataFrame): DataFrame containing 'Date' and 'Sales Volume' columns.\n",
    "        peak_threshold (float, optional): Multiplier for avg. sales volume to define a peak. Defaults to 1.2 (20% above average).\n",
    "        lull_threshold (float, optional): Multiplier for avg. sales volume to define a lull. Defaults to 0.5 (50% below average).\n",
    "        num_promos (int, optional): The maximum number of promotions per month (ignored in this implementation). Defaults to 3.\n",
    "        proximity_days (int, optional): The maximum number of days between dates to consider them part of the same promotional period. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing 'Date' and 'Promotion Type' columns for peak and lull dates.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(sales_data, pd.DataFrame):\n",
    "        raise TypeError(\"sales_data must be a pandas DataFrame\")\n",
    "\n",
    "    # Calculate average sales volume\n",
    "    avg_sales = sales_data['Quantity'].mean()\n",
    "\n",
    "    # Apply thresholds to identify days within peak or lull zones\n",
    "    peak_condition = sales_data['Quantity'] >= avg_sales * peak_threshold\n",
    "    lull_condition = sales_data['Quantity'] <= avg_sales * lull_threshold\n",
    "\n",
    "    # Get top peaks and lulls based on the conditions\n",
    "    peak_days = sales_data[peak_condition].nlargest(num_promos, 'Quantity')['InvoiceDate'].tolist()\n",
    "    lull_days = sales_data[lull_condition].nsmallest(num_promos, 'Quantity')['InvoiceDate'].tolist()\n",
    "\n",
    "    # Group peak and lull days into promotional periods based on proximity using proximity_calculator\n",
    "    peak_periods = proximity_calculator(peak_days)\n",
    "    lull_periods = proximity_calculator(lull_days)\n",
    "\n",
    "    # Create DataFrames for peak and lull periods\n",
    "    peak_df = pd.DataFrame({'Date': [day for period in peak_periods for day in period],\n",
    "                            'Promotion Type': 'Peak'})\n",
    "    lull_df = pd.DataFrame({'Date': [day for period in lull_periods for day in period],\n",
    "                            'Promotion Type': 'Lull'})\n",
    "\n",
    "    # Concatenate peak and lull DataFrames\n",
    "    promo_df = pd.concat([peak_df, lull_df], ignore_index=True)\n",
    "\n",
    "    return promo_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:43.661503900Z",
     "start_time": "2024-03-11T14:24:43.249083700Z"
    }
   },
   "id": "b867fe6de45a0868",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "result =find_promo_days(jan_sales, proximity_days=3) \n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:44.342313400Z",
     "start_time": "2024-03-11T14:24:43.661503900Z"
    }
   },
   "id": "7ea1ca55c2d52cd0",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c891067cedcd77e"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "master_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:44.342313400Z",
     "start_time": "2024-03-11T14:24:44.023521300Z"
    }
   },
   "id": "2aa3b10cc00221f8",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "customer = master_df.groupby(\"CustomerID\").agg(\n",
    "    {\n",
    "        \"TotalPrice\":\"sum\",\n",
    "        \"Quantity\":\"sum\"\n",
    "    }\n",
    ").reset_index()\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:44.342313400Z",
     "start_time": "2024-03-11T14:24:44.144768400Z"
    }
   },
   "id": "a351dcd6098f0e76",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "customer[\"Frequency\"] = master_df.groupby('CustomerID')['InvoiceNo'].count().reset_index()[\"InvoiceNo\"]\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:44.537955200Z",
     "start_time": "2024-03-11T14:24:44.297516100Z"
    }
   },
   "id": "8b5f2c7a6e2a6ee5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "customer['Monetary'] = master_df.groupby('CustomerID')['TotalPrice'].mean().reset_index()['TotalPrice']\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:45.111478500Z",
     "start_time": "2024-03-11T14:24:44.493673400Z"
    }
   },
   "id": "9412f7c032c97556",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "master_df[\"InvoiceDate\"] = pd.to_datetime(master_df[\"InvoiceDate\"])\n",
    "master_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:52.430182600Z",
     "start_time": "2024-03-11T14:24:44.648540400Z"
    }
   },
   "id": "9f82b93fdb64fb23",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "rfm_data = master_df.groupby('CustomerID')['InvoiceDate'].max().reset_index()\n",
    "customer['Recency'] = (rfm_data['InvoiceDate'].max() - rfm_data['InvoiceDate']).dt.days\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:52.582673Z",
     "start_time": "2024-03-11T14:24:52.430182600Z"
    }
   },
   "id": "16251f4930c15679",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:52.634919300Z",
     "start_time": "2024-03-11T14:24:52.555816800Z"
    }
   },
   "id": "74455b298121ac45",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "customer['R_score'] = pd.qcut(customer['Recency'], q=3, labels=[1, 2, 3])  # High recency will have a score of 1\n",
    "customer['F_score'] = pd.qcut(customer['Frequency'], q=3, labels=[1, 2, 3]) \n",
    "customer['M_score'] = pd.qcut(customer['Monetary'], q=3, labels=[1, 2, 3]) \n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:53.197301300Z",
     "start_time": "2024-03-11T14:24:52.587186300Z"
    }
   },
   "id": "466ada99366be605",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Assign Final RFM Score\n",
    "customer['RFM'] = customer[['R_score', 'F_score', 'M_score']].astype(str).agg(''.join, axis=1)\n",
    "customer.drop(columns=['R_score', 'F_score', 'M_score'],inplace=True)\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.067283400Z",
     "start_time": "2024-03-11T14:24:52.706580500Z"
    }
   },
   "id": "d43f8b9271bf8c6d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#Assign Segments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.067283400Z",
     "start_time": "2024-03-11T14:24:52.973119600Z"
    }
   },
   "id": "532ac95133860028",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "customer[\"RFM\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.067283400Z",
     "start_time": "2024-03-11T14:24:53.006224700Z"
    }
   },
   "id": "b41bd97c53ef4ca7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def segment_customers(rfm_column):\n",
    "    \"\"\"Segments customers into broad and subsegments based on RFM scores.\n",
    "\n",
    "    Args:\n",
    "        rfm_column (pd.Series): Series containing RFM scores.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two pandas Series, one for broad segment and one for subsegment.\n",
    "    \"\"\"\n",
    "    broad_segments = []\n",
    "    subsegments = []\n",
    "\n",
    "    for rfm in rfm_column:\n",
    "        recency = int(rfm[0])\n",
    "        frequency = int(rfm[1])\n",
    "        monetary = int(rfm[2])\n",
    "\n",
    "        # Classify into High-Value Segments\n",
    "        if recency == 1 and frequency in [1, 2] and monetary in [1, 2]:\n",
    "            broad_segments.append('HighValue')\n",
    "            if frequency == 1 and monetary == 1:\n",
    "                subsegments.append('Champions')\n",
    "            elif frequency == 1 and monetary == 2:\n",
    "                subsegments.append('LoyalCustomers')\n",
    "            elif frequency == 2 and monetary == 1:\n",
    "                subsegments.append('BigSpenders')\n",
    "        \n",
    "        # Classify into Segments to Nurture\n",
    "        elif recency == 1 and frequency in [3] and monetary in [1, 2]:\n",
    "            broad_segments.append('Nurture')\n",
    "            subsegments.append('NewCustomer')\n",
    "        elif recency == 2 and frequency in [1, 2] and monetary in [1, 2]:\n",
    "            broad_segments.append('Nurture')\n",
    "            subsegments.append('Promising')\n",
    "        elif recency == 2 and frequency in [3] and monetary in [2]:\n",
    "            broad_segments.append('Nurture')\n",
    "            subsegments.append('NeedsAttention')\n",
    "        \n",
    "        # Classify into At-Risk Segments\n",
    "        else:\n",
    "            broad_segments.append('Risk')\n",
    "            if recency == 1 and frequency in [3] and monetary in [3]:\n",
    "                subsegments.append(\"CantLoseThem\")\n",
    "            elif recency == 2 and frequency in [3] and monetary in [3]:\n",
    "                subsegments.append('AboutToSleep')\n",
    "            else:\n",
    "                subsegments.append('LostCustomers')\n",
    "\n",
    "    return pd.Series(broad_segments, name='Broad Segment'), pd.Series(subsegments, name='Subsegment')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.067283400Z",
     "start_time": "2024-03-11T14:24:53.065835500Z"
    }
   },
   "id": "e99833c0c5519d1a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def segment_customers(rfm_column):\n",
    "    \"\"\"Segments customers into broad and subsegments based on RFM scores for a general retail store.\n",
    "\n",
    "    Args:\n",
    "        rfm_column (pd.Series): Series containing RFM scores.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two pandas Series, one for broad segment and one for subsegment.\n",
    "    \"\"\"\n",
    "    broad_segments = []\n",
    "    subsegments = []\n",
    "\n",
    "    # Define dictionaries for each segment and subsegment\n",
    "    high_value_segments = {\n",
    "        (1, 1, 1): 'Loyal Champions', (1, 1, 2): 'Frequent Spenders', (1, 1, 3): 'Rising Stars',\n",
    "        (1, 2, 1): 'Recent Big Spenders', (1, 2, 2): 'Frequent Spenders', (1, 2, 3): 'Rising Stars',\n",
    "        (1, 3, 1): 'Rekindled Spenders', (1, 3, 2): 'Needs Attention', (1, 3, 3): 'Value Seekers',\n",
    "        (2, 3, 1): 'Big Ticket Buyers'\n",
    "    }\n",
    "    nurture_segments = {\n",
    "        (2, 2, 2): 'Occasional Spenders', (2, 2, 3): 'Value Seekers', (2, 3, 2): 'Sleeping Giants',\n",
    "        (2, 3, 3): 'Value Seekers', (1, 3, 3): 'Needs Attention',\n",
    "        (2, 1, 2): 'Win-Back Target', (2, 1, 3): 'Win-Back Target',  \n",
    "        (2, 2, 1): 'Potential Upscale'\n",
    "    }\n",
    "    risk_segments = {\n",
    "        (3, 1, 1): 'Lost Loyalists', (3, 1, 2): 'Fading Interest', (3, 1, 3): 'One-Time Buyers',\n",
    "        (3, 2, 1): 'At-Risk Customers', (3, 2, 2): 'Fading Interest', (3, 2, 3): 'One-Time Buyers',\n",
    "        (3, 3, 1): 'Window Shoppers', (3, 3, 2): 'Window Shoppers', (3, 3, 3): 'One-Time Buyers',\n",
    "        (2, 1, 1): 'At-Risk Customers'   \n",
    "    }\n",
    "\n",
    "    all_segments = list(high_value_segments.keys()) + list(nurture_segments.keys()) + list(risk_segments.keys())\n",
    "    all_subsegments = list(high_value_segments.values()) + list(nurture_segments.values()) + list(risk_segments.values())\n",
    "\n",
    "    # Check if the lengths of segment and subsegment lists match\n",
    "    assert len(all_segments) == len(all_subsegments), \"Lengths of segment and subsegment lists must match\"\n",
    "\n",
    "    for rfm in rfm_column:\n",
    "        recency = int(rfm[0])\n",
    "        frequency = int(rfm[1])\n",
    "        monetary = int(rfm[2])\n",
    "        \n",
    "        if (recency, frequency, monetary) in all_segments:\n",
    "            broad_segments.append(\n",
    "                'High Value' if (recency, frequency, monetary) in high_value_segments.keys()\n",
    "                else 'Nurture' if (recency, frequency, monetary) in nurture_segments.keys()\n",
    "                else 'Risk'\n",
    "            )\n",
    "            subsegments.append(all_subsegments[all_segments.index((recency, frequency, monetary))])\n",
    "        else:\n",
    "            broad_segments.append('Unknown')\n",
    "            subsegments.append('Unknown')\n",
    "\n",
    "    return pd.Series(broad_segments, name='Broad Segment'), pd.Series(subsegments, name='Subsegment')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "379fc3d8f63f781b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "customer[\"Segment\"], customer[\"Subsegment\"] = segment_customers(customer['RFM'])\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.164810900Z",
     "start_time": "2024-03-11T14:24:53.125112900Z"
    }
   },
   "id": "dc3ac94f1dafe932",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "high_value_df = customer[customer['Segment'] == 'HighValue']\n",
    "risk_df = customer[customer['Segment'] == 'Risk']\n",
    "nurture_df = customer[customer['Segment'] == 'Nurture']\n",
    "high_value_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.280576700Z",
     "start_time": "2024-03-11T14:24:53.215697Z"
    }
   },
   "id": "dd9c81f7741aaf7e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def segment_customers(rfm_column):\n",
    "    \"\"\"Segments customers into broad and subsegments based on RFM scores.\n",
    "\n",
    "    Args:\n",
    "        rfm_column (pd.Series): Series containing RFM scores.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two pandas Series, one for broad segment and one for subsegment.\n",
    "    \"\"\"\n",
    "    broad_segments = []\n",
    "    subsegments = []\n",
    "\n",
    "    # Define arrays for each segment and subsegment\n",
    "    high_value_segments = [\n",
    "        (1, 1, 1), (1, 1, 2), (1, 1, 3), \n",
    "        (1, 2, 1), (1, 2, 2), (1, 2, 3), \n",
    "        (1, 3, 1), (1, 3, 2), (1, 3, 3)\n",
    "    ]\n",
    "    high_value_subsegments = [\n",
    "        'Champions', 'Loyalists', 'High Potential', \n",
    "        'Big Ticket', 'Regular Spenders', 'Emerging Loyalists'\n",
    "    ]\n",
    "    \n",
    "    nurture_segments = [\n",
    "        (1, 3, 3), (2, 1, 3), (2, 2, 2), \n",
    "        (2, 2, 3), (2, 3, 2), (2, 3, 3)\n",
    "    ]\n",
    "    nurture_subsegments = [\n",
    "        'Needs a Spark', 'Upscale Focus', 'Consistent Spender', \n",
    "        'Potential Upscale', 'Win-Back Target', 'Casual Shopper'\n",
    "    ]\n",
    "    \n",
    "    risk_segments = [\n",
    "        (1, 3, 1), (1, 3, 2), (2, 3, 1), \n",
    "        (3, 1, 1), (3, 1, 2), (3, 1, 3), \n",
    "        (3, 2, 1), (3, 2, 2), (3, 2, 3),\n",
    "        (3, 3, 1), (3, 3, 2), (3, 3, 3)\n",
    "    ]\n",
    "    risk_subsegments = [\n",
    "        'Wake-Up Call', 'Slipping Away', 'Dormant Upscale',\n",
    "        'One-offs', 'One-offs', 'One-offs', \n",
    "        'Sporadic', 'Sporadic', 'Sporadic',\n",
    "        'Lost Cause', 'Lost Cause', 'Lost Cause'\n",
    "    ]\n",
    "\n",
    "    all_segments = high_value_segments + nurture_segments + risk_segments\n",
    "    all_subsegments = high_value_subsegments + nurture_subsegments + risk_subsegments\n",
    "    for i, combination in enumerate(all_segments):\n",
    "     print(f\"Index {i}: Combination {combination}\")\n",
    "\n",
    "\n",
    "    for rfm in rfm_column:\n",
    "        recency = int(rfm[0])\n",
    "        frequency = int(rfm[1])\n",
    "        monetary = int(rfm[2])\n",
    "        \n",
    " \n",
    "\n",
    "        if (recency, frequency, monetary) in all_segments:\n",
    "            broad_segments.append(\n",
    "                'High Value' if (recency, frequency, monetary) in high_value_segments\n",
    "                else 'Nurture' if (recency, frequency, monetary) in nurture_segments\n",
    "                else 'Risk'\n",
    "            )\n",
    "            subsegments.append(all_subsegments[all_segments.index((recency, frequency, monetary))])\n",
    "        else:\n",
    "            broad_segments.append('Unknown')\n",
    "            subsegments.append('Unknown')\n",
    "\n",
    "    return pd.Series(broad_segments, name='Broad Segment'), pd.Series(subsegments, name='Subsegment')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.280576700Z",
     "start_time": "2024-03-11T14:24:53.288954500Z"
    }
   },
   "id": "9a81543151e3165e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "#Merging customer data with segments\n",
    "segmented = master_df[[\"CustomerID\",\"InvoiceNo\",\"StockCode\"]]\n",
    "segmented"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.280576700Z",
     "start_time": "2024-03-11T14:24:53.400391600Z"
    }
   },
   "id": "e2fa7b3072c5964a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "customers = customer[[\"CustomerID\",\"Segment\"]]\n",
    "customers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.280576700Z",
     "start_time": "2024-03-11T14:24:53.473035600Z"
    }
   },
   "id": "be229153f0c46305",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "#Convert customer ids to strings\n",
    "customers[\"CustomerID\"] = customers[\"CustomerID\"].astype(object)\n",
    "# segmented[\"CustomerID\"] = segmented[\"CustomerID\"].astype(object)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.280576700Z",
     "start_time": "2024-03-11T14:24:53.517285800Z"
    }
   },
   "id": "74dea1c4cd6646b5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "segmented"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.280576700Z",
     "start_time": "2024-03-11T14:24:53.573090100Z"
    }
   },
   "id": "f1cda60dacc4f4b9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "master_df[[\"CustomerID\",\"InvoiceNo\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.280576700Z",
     "start_time": "2024-03-11T14:24:53.622583100Z"
    }
   },
   "id": "7b01a6316441a167",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "transaction_df = pd.merge(segmented,customers,on=\"CustomerID\",how=\"left\")\n",
    "transaction_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:54.480777900Z",
     "start_time": "2024-03-11T14:24:53.680814400Z"
    }
   },
   "id": "ff94952d1b420218",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "#Divide data for offers\n",
    "high_value_df = transaction_df[transaction_df['Segment'] == 'HighValue']\n",
    "risk_df = transaction_df[transaction_df['Segment'] == 'Risk']\n",
    "nurture_df = transaction_df[transaction_df['Segment'] == 'Nurture']\n",
    "high_value_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:24:55.520512500Z",
     "start_time": "2024-03-11T14:24:54.183048400Z"
    }
   },
   "id": "bed642d826be08ed",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Promotional Offers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da8e27ce667aae8a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Aggregate Transctions\n",
    "def aggregate_transactions(df):\n",
    "     transactions = df.groupby([\"InvoiceNo\",\"CustomerID\"]).agg({\"StockCode\": lambda s : list(set(s))})\n",
    "     return transactions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T22:04:10.963486200Z",
     "start_time": "2024-05-09T22:04:10.900801700Z"
    }
   },
   "id": "9cf6bc0881c81c27",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from fpgrowth_py import fpgrowth\n",
    "\n",
    "#Generating  Association Rules\n",
    "def get_rules(df):\n",
    "    hbasket = aggregate_transactions(df)\n",
    "    freqItemSet, rules = fpgrowth(hbasket['StockCode'].values, minSupRatio=0.01, minConf=0.8)\n",
    "    print('Number of rules generated : ', len(rules))\n",
    "    association=pd.DataFrame(rules,columns =['basket','next_product','proba']) \n",
    "    association=association.sort_values(by='proba',ascending=False)\n",
    "    \n",
    "    return association\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T22:04:17.533497300Z",
     "start_time": "2024-05-09T22:04:17.423326200Z"
    }
   },
   "id": "7a9cff8c02e14b6a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Get Rules for high Value Segments\n",
    "h_assoc = get_rules(risk_df)\n",
    "h_assoc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:25:55.716029Z",
     "start_time": "2024-03-11T14:24:54.830663Z"
    }
   },
   "id": "7ee04a0d6230821c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Get frequent item sets\n",
    "def get_most_frequent_itemsets(df):\n",
    "    # Group by InvoiceNo and CustomerID and aggregate unique StockCodes into lists\n",
    "    hbasket = aggregate_transactions(df)\n",
    "    \n",
    "    # Run FP-Growth algorithm to find frequent itemsets\n",
    "    freqItemSet, _ = fpgrowth(hbasket['StockCode'].values, minSupRatio=0.01, minConf=0.7)\n",
    "    \n",
    "    # Sort items within each itemset and convert frequent itemsets to DataFrame\n",
    "    frequent_itemsets_df = pd.DataFrame({'Frequent Itemset': [sorted(itemset) for itemset in freqItemSet]})\n",
    "    \n",
    "    # Remove duplicates (after sorting, duplicate itemsets will be identical)\n",
    "    frequent_itemsets_df = frequent_itemsets_df.drop_duplicates(subset='Frequent Itemset')\n",
    "    \n",
    "    # Filter out itemsets with less than 2 items\n",
    "    frequent_itemsets_df = frequent_itemsets_df[frequent_itemsets_df['Frequent Itemset'].apply(len) > 2]\n",
    "    \n",
    "    return frequent_itemsets_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T22:06:01.577751500Z",
     "start_time": "2024-05-09T22:06:01.546125800Z"
    }
   },
   "id": "190c2f833ed48468",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# xg = get_most_frequent_itemsets(nurture_df)\n",
    "# xg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:25:55.910773700Z",
     "start_time": "2024-03-11T14:25:55.731315700Z"
    }
   },
   "id": "37dbe9bb3cae37a5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "#Get Buy One,Get One Discounted Bundles\n",
    "#Returns product bundles\n",
    "def get_bogd_bundles(df):\n",
    "        hbasket = aggregate_transactions(df)\n",
    "        freqItemSet, rules = fpgrowth(hbasket['StockCode'].values, minSupRatio=0.01, minConf=0.9)\n",
    "        print('Number of rules generated : ', len(rules))\n",
    "        \n",
    "        association=pd.DataFrame(rules,columns =['basket','next_product','proba']) \n",
    "        association=association.sort_values(by='proba',ascending=False)\n",
    "    \n",
    "        return association\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:25:56.017499600Z",
     "start_time": "2024-03-11T14:25:55.810704Z"
    }
   },
   "id": "a81822ae4dc1c386",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Buy One,Get One Discounted\n",
    "def bogd(product_bundles, order):\n",
    "    # Check if any bundle matches the items in the order\n",
    "    matching_bundles = product_bundles[product_bundles['basket'].apply(lambda x: set(x).issubset(set(order)))]\n",
    "\n",
    "    if matching_bundles.empty:\n",
    "        print(\"Order Not Eligible For Discount\")\n",
    "        return []\n",
    "\n",
    "    # Extract and return consequent products from matching bundles\n",
    "    recommended_products = matching_bundles['next_product'].tolist()\n",
    "    recommended_item_codes = [item for sublist in recommended_products for item in sublist]\n",
    "    return recommended_item_codes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:25:56.122752700Z",
     "start_time": "2024-03-11T14:25:55.872989Z"
    }
   },
   "id": "bad13f1b6bdd77a5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "#Try for high value segments\n",
    "gx = get_bogd_bundles(high_value_df)\n",
    "gx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:02.891640500Z",
     "start_time": "2024-03-11T14:25:55.936486200Z"
    }
   },
   "id": "fcae2a8d67f6b15d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Test\n",
    "order = {'21080','45373', '21086','67262','63773'}\n",
    "bogd(gx, order)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:03.154029700Z",
     "start_time": "2024-03-11T14:26:02.865973500Z"
    }
   },
   "id": "f8b3d8f0c54e9793",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Fixed amount discount\n",
    "def apply_fixed_discount(total_amount, fixed_discount):\n",
    "    \"\"\"\n",
    "    Apply a fixed amount discount to the total purchase amount.\n",
    "\n",
    "    Parameters:\n",
    "    - total_amount (float): Total purchase amount before discount.\n",
    "    - fixed_discount (float): Fixed discount amount to be subtracted.\n",
    "\n",
    "    Returns:\n",
    "    - discounted_amount (float): Total purchase amount after applying the fixed discount.\n",
    "    \"\"\"\n",
    "    discounted_amount = max(total_amount - fixed_discount, 0)  # Ensure discounted amount doesn't go below zero\n",
    "    return discounted_amount\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:15:51.489958400Z",
     "start_time": "2024-05-10T11:15:51.447955900Z"
    }
   },
   "id": "54f03e3995f1f8f3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "#Bundled Discounts\n",
    "def apply_bundle_discount(bundle, discount_df):\n",
    "    \"\"\"\n",
    "    Apply discounts to each item in a product bundle and return the final price.\n",
    "\n",
    "    Parameters:\n",
    "    - bundle (list): List of product IDs in the bundle.\n",
    "    - discount_df (DataFrame): DataFrame containing product IDs and their discounts.\n",
    "\n",
    "    Returns:\n",
    "    - final_price (float): Final price of the bundle after applying discounts.\n",
    "    \"\"\"\n",
    "    final_price = 0\n",
    "    \n",
    "    # Iterate through each item in the bundle\n",
    "    for item in bundle:\n",
    "        # Look up the discount for the item in the discount DataFrame\n",
    "        item_discount = discount_df.loc[discount_df['ProductID'] == item, 'Discount'].values\n",
    "        \n",
    "        # If the item is found in the discount DataFrame, apply the discount\n",
    "        if len(item_discount) > 0:\n",
    "            item_discount = item_discount[0]  # Extract the discount value\n",
    "            # Assume original price of the item is 0 if not found in discount DataFrame\n",
    "            original_price = discount_df.loc[discount_df['ProductID'] == item, 'Price'].values[0]\n",
    "            # Apply the discount to the original price of the item\n",
    "            discounted_price = original_price * (1 - item_discount)\n",
    "            # Add the discounted price to the final price\n",
    "            final_price += discounted_price\n",
    "        else:\n",
    "            print(f\"Discount not found for item {item}. Assuming original price.\")\n",
    "\n",
    "    return final_price\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:04.236781100Z",
     "start_time": "2024-03-11T14:26:03.270764100Z"
    }
   },
   "id": "ad6ce84c2132d6ac",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#Test Bundled Discount\n",
    "# Dummy Discount Data\n",
    "# Define the discount data\n",
    "discount_data = {\n",
    "    'ProductID': ['20725', '20727', '22383', '20728', '85099B', '23209', '23203','23170', '23171', '23172'],\n",
    "    'Price': [5.0, 8.0, 10.0, 7.0, 12.0, 9.0, 6.0,15.0, 20.0, 25.0],\n",
    "    'Discount': [0.1, 0.2, 0.15, 0.1, 0.25, 0.2, 0.15,0.1, 0.2, 0.15]  # Assuming sample discount percentages\n",
    "}\n",
    "\n",
    "# Create the discount DataFrame\n",
    "discount_df = pd.DataFrame(discount_data)\n",
    "discount_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T19:15:35.780431700Z",
     "start_time": "2024-05-07T19:15:35.376194100Z"
    }
   },
   "id": "9b2aa4c861a8b6c6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "discount_df.to_csv(\"discount_sample_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T19:16:48.486433300Z",
     "start_time": "2024-05-07T19:16:47.753512300Z"
    }
   },
   "id": "3b2adfda27d82479",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# # Example product bundle\n",
    "# bundle = xg[\"Frequent Itemset\"][107]\n",
    "# \n",
    "# # Calculate final price of the bundle after applying discounts\n",
    "# final_price = apply_bundle_discount(bundle, discount_df)\n",
    "# print(\"Final price of the bundle after applying discounts:\", final_price)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:04.267145600Z",
     "start_time": "2024-03-11T14:26:03.389091500Z"
    }
   },
   "id": "c0eedcd418938e55",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Get Tiered Discount\n",
    "def calculate_tiered_discount(total_price, tiers):\n",
    "    discount = 0\n",
    "    for tier in tiers:\n",
    "        if total_price >= tier['min_amount']:\n",
    "            discount = tier['discount']\n",
    "        else:\n",
    "            break\n",
    "    return total_price - (total_price * (discount / 100))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T19:07:02.143222400Z",
     "start_time": "2024-05-18T19:07:02.055517900Z"
    }
   },
   "id": "b3dbb1c2f2d23ee7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Example tiers\n",
    "tiers = [\n",
    "    {'min_amount': 0, 'discount': 0},   # Tier 1: $0 - $100 (0% discount)\n",
    "    {'min_amount': 101, 'discount': 5}, # Tier 2: $101 - $200 (5% discount)\n",
    "    {'min_amount': 201, 'discount': 10} # Tier 3: $201 and above (10% discount)\n",
    "]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T19:13:25.618147300Z",
     "start_time": "2024-05-18T19:13:25.598049700Z"
    }
   },
   "id": "386f278ad80002eb",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Example usage\n",
    "total_price = 150\n",
    "discounted_amount = calculate_tiered_discount(total_price, tiers)\n",
    "print(f\"Discounted Amount: ${discounted_amount}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T20:18:19.761248900Z",
     "start_time": "2024-05-18T20:18:19.655071900Z"
    }
   },
   "id": "2e043a6e9572afd4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# Loyalty Points\n",
    "def calculate_loyalty_points(total_price, points_per_dollar):\n",
    "    return total_price * points_per_dollar"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:04.267805800Z",
     "start_time": "2024-03-11T14:26:03.633595800Z"
    }
   },
   "id": "936d6fe2acdcb835",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# Example usage\n",
    "total_price = 150\n",
    "points_per_dollar = 2  # Assume 2 points per dollar spent\n",
    "loyalty_points = calculate_loyalty_points(total_price, points_per_dollar)\n",
    "print(f\"Loyalty Points Earned: {loyalty_points}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:04.267805800Z",
     "start_time": "2024-03-11T14:26:03.704993500Z"
    }
   },
   "id": "a0b553c2f25af9fc",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "def get_bundles(df):\n",
    "    hbasket = aggregate_transactions(df)\n",
    "    freqItemSet, rules = fpgrowth(hbasket['StockCode'].values, minSupRatio=0.01, minConf=0.9)\n",
    "    print('Number of rules generated: ', len(rules))\n",
    "    \n",
    "    associations = pd.DataFrame(rules, columns=['basket', 'next_product', 'proba'])\n",
    "    associations = associations.sort_values(by='proba', ascending=False)\n",
    "    \n",
    "    itemsets = pd.DataFrame({'itemset': freqItemSet})\n",
    "    itemsets['support'] = itemsets['itemset'].apply(lambda x: hbasket[hbasket['StockCode'].apply(lambda y: set(x).issubset(set(y)))].shape[0] / len(hbasket))\n",
    "    itemsets = itemsets[itemsets['itemset'].apply(lambda x: len(x) > 1)]  # Filter out itemsets with only one item\n",
    "    itemsets = itemsets.sort_values(by='support', ascending=False)  # Sort itemsets by support\n",
    "    \n",
    "    return associations, itemsets\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:04.267805800Z",
     "start_time": "2024-03-11T14:26:03.851352900Z"
    }
   },
   "id": "f725992910dfbb05",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Function to generate random profit margins\n",
    "def generate_profit_margin(unit_price):\n",
    "    # Generate a random percentage between 5% and 20%\n",
    "    random_percentage = np.random.uniform(0.05, 0.20)\n",
    "    # Calculate the profit margin\n",
    "    profit_margin = unit_price * random_percentage\n",
    "    return profit_margin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:26:15.295903500Z",
     "start_time": "2024-03-11T14:26:14.592847100Z"
    }
   },
   "id": "38c53f7c69a0cf88",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
