{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T11:32:29.171065Z",
     "start_time": "2024-06-11T11:32:29.132654Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from fpgrowth_py import fpgrowth\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import uuid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:05:29.815262400Z",
     "start_time": "2024-05-15T04:05:29.673073100Z"
    }
   },
   "id": "f7dce69273ee883b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv(\"express.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:43:42.239079100Z",
     "start_time": "2024-05-23T23:43:39.843113800Z"
    }
   },
   "id": "5b670808023e3873",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Remove Credit/Cancelled transactions\n",
    "df = df[df[\"OnCredit\"]==False]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:31.183575300Z",
     "start_time": "2024-05-08T13:14:31.004457800Z"
    }
   },
   "id": "3466ba2ed1b6181c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:31.199672300Z",
     "start_time": "2024-05-08T13:14:31.183575300Z"
    }
   },
   "id": "2b7ade9a5fb3b3bb",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = df[[\"InvoiceDate\",\"InvoiceNo\",\"CustomerID\",\"StockCode\",\"UnitPrice\",\"Quantity\",\"TotalPrice\"]]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:31.389936900Z",
     "start_time": "2024-05-08T13:14:31.224655500Z"
    }
   },
   "id": "f131084010980514",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Group transactions by CustomerID then aggregate total price and quantity for them\n",
    "customer = df.groupby(\"CustomerID\").agg(\n",
    "    {\n",
    "        \"TotalPrice\":\"sum\",\n",
    "        \"Quantity\":\"sum\"\n",
    "    }\n",
    ").reset_index()\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:31.789829300Z",
     "start_time": "2024-05-08T13:14:31.397585800Z"
    }
   },
   "id": "adc33c613d2d0d26",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Add frequency\n",
    "customer[\"Frequency\"] = df.groupby('CustomerID')['InvoiceNo'].count().reset_index()[\"InvoiceNo\"]\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:32.044268200Z",
     "start_time": "2024-05-08T13:14:31.773993100Z"
    }
   },
   "id": "305f580aba59c7c1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Add Monetary\n",
    "customer['Monetary'] =df.groupby('CustomerID')['TotalPrice'].mean().reset_index()['TotalPrice']\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:32.311091200Z",
     "start_time": "2024-05-08T13:14:32.165667600Z"
    }
   },
   "id": "7a8641119f950776",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Add Recency\n",
    "#First get date\n",
    "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
    "rfm_data =df.groupby('CustomerID')['InvoiceDate'].max().reset_index()\n",
    "customer['Recency'] = (rfm_data['InvoiceDate'].max() - rfm_data['InvoiceDate']).dt.days\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:42.336089800Z",
     "start_time": "2024-05-08T13:14:32.319681800Z"
    }
   },
   "id": "393b563350035cc9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Now add RFM scores \n",
    "customer['R_score'] = pd.qcut(customer['Recency'], q=3, labels=[1, 2, 3])  # High recency will have a score of 1\n",
    "customer['F_score'] = pd.qcut(customer['Frequency'], q=3, labels=[1, 2, 3]) \n",
    "customer['M_score'] = pd.qcut(customer['Monetary'], q=3, labels=[1, 2, 3]) \n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:42.479310Z",
     "start_time": "2024-05-08T13:14:42.332612700Z"
    }
   },
   "id": "e14a9669d04280c4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Assign Final RFM Score\n",
    "customer['RFM'] = customer[['R_score', 'F_score', 'M_score']].astype(str).agg(''.join, axis=1)\n",
    "customer.drop(columns=['R_score', 'F_score', 'M_score'],inplace=True)\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:45.274547500Z",
     "start_time": "2024-05-08T13:14:42.421803400Z"
    }
   },
   "id": "9ebaf45fefc52ff1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def segment_customers(rfm_column):\n",
    "    \"\"\"Segments customers into broad and subsegments based on RFM scores for a general retail store.\n",
    "\n",
    "    Args:\n",
    "        rfm_column (pd.Series): Series containing RFM scores.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two pandas Series, one for broad segment and one for subsegment.\n",
    "    \"\"\"\n",
    "    broad_segments = []\n",
    "    subsegments = []\n",
    "\n",
    "    # Define dictionaries for each segment and subsegment\n",
    "    high_value_segments = {\n",
    "        (1, 1, 1): 'Loyal Champions', (1, 1, 2): 'Frequent Spenders', (1, 1, 3): 'Rising Stars',\n",
    "        (1, 2, 1): 'Recent Big Spenders', (1, 2, 2): 'Frequent Spenders', (1, 2, 3): 'Rising Stars',\n",
    "        (1, 3, 1): 'Rekindled Spenders', (1, 3, 2): 'Needs Attention', (1, 3, 3): 'Value Seekers',\n",
    "        (2, 3, 1): 'Big Ticket Buyers'\n",
    "    }\n",
    "    nurture_segments = {\n",
    "        (2, 2, 2): 'Occasional Spenders', (2, 2, 3): 'Value Seekers', (2, 3, 2): 'Sleeping Giants',\n",
    "        (2, 3, 3): 'Value Seekers', (1, 3, 3): 'Needs Attention',\n",
    "        (2, 1, 2): 'Win-Back Target', (2, 1, 3): 'Win-Back Target',  \n",
    "        (2, 2, 1): 'Potential Upscale'\n",
    "    }\n",
    "    risk_segments = {\n",
    "        (3, 1, 1): 'Lost Loyalists', (3, 1, 2): 'Fading Interest', (3, 1, 3): 'One-Time Buyers',\n",
    "        (3, 2, 1): 'At-Risk Customers', (3, 2, 2): 'Fading Interest', (3, 2, 3): 'One-Time Buyers',\n",
    "        (3, 3, 1): 'Window Shoppers', (3, 3, 2): 'Window Shoppers', (3, 3, 3): 'One-Time Buyers',\n",
    "        (2, 1, 1): 'At-Risk Customers'   \n",
    "    }\n",
    "\n",
    "    all_segments = list(high_value_segments.keys()) + list(nurture_segments.keys()) + list(risk_segments.keys())\n",
    "    all_subsegments = list(high_value_segments.values()) + list(nurture_segments.values()) + list(risk_segments.values())\n",
    "\n",
    "    # Check if the lengths of segment and subsegment lists match\n",
    "    assert len(all_segments) == len(all_subsegments), \"Lengths of segment and subsegment lists must match\"\n",
    "\n",
    "    for rfm in rfm_column:\n",
    "        recency = int(rfm[0])\n",
    "        frequency = int(rfm[1])\n",
    "        monetary = int(rfm[2])\n",
    "        \n",
    "        if (recency, frequency, monetary) in all_segments:\n",
    "            broad_segments.append(\n",
    "                'High Value' if (recency, frequency, monetary) in high_value_segments.keys()\n",
    "                else 'Nurture' if (recency, frequency, monetary) in nurture_segments.keys()\n",
    "                else 'Risk'\n",
    "            )\n",
    "            subsegments.append(all_subsegments[all_segments.index((recency, frequency, monetary))])\n",
    "        else:\n",
    "            broad_segments.append('Unknown')\n",
    "            subsegments.append('Unknown')\n",
    "\n",
    "    return pd.Series(broad_segments, name='Broad Segment'), pd.Series(subsegments, name='Subsegment')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:46.063932100Z",
     "start_time": "2024-05-08T13:14:45.729907900Z"
    }
   },
   "id": "e9908dcaafdbfb7d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#Segment the customers\n",
    "customer[\"Segment\"], customer[\"Subsegment\"] = segment_customers(customer['RFM'])\n",
    "customer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:47.849525400Z",
     "start_time": "2024-05-08T13:14:47.224810600Z"
    }
   },
   "id": "cc9d69690854cb7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#Merging segments into final df\n",
    "segmented = df[[\"CustomerID\",\"InvoiceNo\",\"StockCode\"]]\n",
    "segmented"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:48.322731800Z",
     "start_time": "2024-05-08T13:14:47.929755400Z"
    }
   },
   "id": "b60a98d9f1b66e5b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "x = customer[[\"CustomerID\",\"Segment\",\"Subsegment\"]]\n",
    "x.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:48.449451500Z",
     "start_time": "2024-05-08T13:14:48.322731800Z"
    }
   },
   "id": "28893af4b679dd60",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "transaction_df = pd.merge(segmented,x,on=\"CustomerID\",how=\"left\")\n",
    "transaction_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:49.769742800Z",
     "start_time": "2024-05-08T13:14:48.412728500Z"
    }
   },
   "id": "a4fc1f455f94e4cc",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "high_value_df = customer[customer['Segment'] == 'High Value']\n",
    "risk_df = customer[customer['Segment'] == 'Risk']\n",
    "nurture_df = customer[customer['Segment'] == 'Nurture']\n",
    "high_value_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:14:50.059739200Z",
     "start_time": "2024-05-08T13:14:49.779327100Z"
    }
   },
   "id": "71e9f2e1425f8229",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def get_segment_transactions(df):\n",
    "    # Filter data based on segments\n",
    "    high_value_df = df[df['Segment'] == 'High Value']\n",
    "    risk_df = df[df['Segment'] == 'Risk']\n",
    "    nurture_df = df[df['Segment'] == 'Nurture']\n",
    "    \n",
    "    # Write each segment to a CSV file\n",
    "    high_value_df.to_csv('high_value_transactions.csv', index=False)\n",
    "    risk_df.to_csv('risk_transactions.csv', index=False)\n",
    "    nurture_df.to_csv('nurture_transactions.csv', index=False)\n",
    "\n",
    "    return 'high_value_transactions.csv', 'risk_transactions.csv', 'nurture_transactions.csv'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:21:41.681364400Z",
     "start_time": "2024-05-08T13:21:40.911253700Z"
    }
   },
   "id": "971eb8884df107d3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "get_segment_transactions(transaction_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:22:39.506840200Z",
     "start_time": "2024-05-08T13:22:14.056260400Z"
    }
   },
   "id": "ed4cc07aa8210651",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "transaction_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:33:09.373821600Z",
     "start_time": "2024-05-08T13:33:09.309786300Z"
    }
   },
   "id": "9a3d2b2ffa351b38",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Function to generate random profit margins\n",
    "def generate_profit_margin(unit_price, min_percentage=0.05, max_percentage=0.20):\n",
    "    # Generate a random percentage between min_percentage and max_percentage\n",
    "    random_percentage = np.random.uniform(min_percentage, max_percentage)\n",
    "    # Calculate the profit margin\n",
    "    profit_margin = unit_price * random_percentage\n",
    "    return profit_margin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:51:26.073003600Z",
     "start_time": "2024-05-08T13:51:26.021236400Z"
    }
   },
   "id": "3121834730319493",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import numpy as np\n",
    "\n",
    "def set_profit_margins(df, min_percentage=0.05, max_percentage=0.20, output_file=\"profit_margins.csv\"):\n",
    "    data = df[[\"StockCode\", \"UnitPrice\"]]\n",
    "    # Drop duplicates based on the 'StockCode' column\n",
    "    data = data.drop_duplicates(subset=['StockCode'])\n",
    "    # Define a function to generate profit margins\n",
    "    def generate_profit_margin(unit_price):\n",
    "        # Generate a random percentage between min_percentage and max_percentage\n",
    "        random_percentage = np.random.uniform(min_percentage, max_percentage)\n",
    "        # Calculate the profit margin\n",
    "        profit_margin = unit_price * random_percentage\n",
    "        return profit_margin\n",
    "    # Apply the generate_profit_margin function to each row of the 'UnitPrice' column\n",
    "    data['ProfitMargin'] = data['UnitPrice'].apply(generate_profit_margin)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    data.to_csv(output_file, index=False)\n",
    "    return output_file\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:54:39.448380600Z",
     "start_time": "2024-05-08T13:54:39.411216600Z"
    }
   },
   "id": "ae0f8527885de7a9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T19:15:47.584080300Z",
     "start_time": "2024-05-11T19:15:47.425002300Z"
    }
   },
   "id": "61a32109eb76194c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "set_profit_margins(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T13:55:16.692479200Z",
     "start_time": "2024-05-08T13:55:16.599413200Z"
    }
   },
   "id": "9669e0366163adf6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df['id'] = [uuid.uuid4() for _ in range(len(df))]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T19:16:19.033794200Z",
     "start_time": "2024-05-11T19:16:16.284768400Z"
    }
   },
   "id": "c53e973b60bb09a0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def set_profit_margins_and_discounts(df, min_margin=0.02, min_discount=0.02, max_discount=0.50, output_file=\"products_data.csv\"):\n",
    "    \"\"\"\n",
    "    This function randomly assigns profit margins and discounts to products in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing product data with columns:\n",
    "            - StockCode (str): Unique product code.\n",
    "            - UnitPrice (float): Original unit price of the product.\n",
    "        min_margin (float, optional): Minimum profit margin percentage (default: 0.02).\n",
    "        min_discount (float, optional): Minimum discount percentage (default: 0.02).\n",
    "        max_discount (float, optional): Maximum discount percentage (default: 0.50).\n",
    "        output_file (str, optional): Name of the output CSV file (default: \"profit_margins_and_discounts.csv\").\n",
    "\n",
    "    Returns:\n",
    "        str: Name of the output CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    data = df[[\"id\",\"Description\",\"StockCode\", \"UnitPrice\"]]\n",
    "    # Drop duplicates based on the 'StockCode' column\n",
    "    data = data.drop_duplicates(subset=['StockCode'])\n",
    "\n",
    "    def generate_profit_margin(unit_price):\n",
    "        \"\"\"\n",
    "        Generates a random profit margin for a given unit price.\n",
    "\n",
    "        Args:\n",
    "            unit_price (float): Original unit price of the product.\n",
    "\n",
    "        Returns:\n",
    "            float: Randomly generated profit margin.\n",
    "        \"\"\"\n",
    "        # Generate a random percentage for profit margin\n",
    "        random_margin = np.random.uniform(min_margin, 1.0)  # Ensure profit margin is at least 2%\n",
    "        # Calculate the profit margin\n",
    "        profit_margin = unit_price * random_margin\n",
    "        profit_margin = round(profit_margin,2)\n",
    "        return profit_margin\n",
    "\n",
    "    def calculate_discounted_price(unit_price, profit_margin):\n",
    "        \"\"\"\n",
    "        Calculates a random discount that maintains a minimum profit margin.\n",
    "\n",
    "        Args:\n",
    "            unit_price (float): Original unit price of the product.\n",
    "            profit_margin (float): Current profit margin of the product.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tuple containing the discounted price (float) and discount percentage (float).\n",
    "        \"\"\"\n",
    "        max_discount = 1 - profit_margin / unit_price  # Maximum discount allowed to maintain minimum profit\n",
    "\n",
    "        # Generate random discount between min_discount and max_discount\n",
    "        discount = np.random.uniform(min_discount, max_discount)\n",
    "        \n",
    "         # Round the discount to 2 decimal places\n",
    "        discount = round(discount, 2)\n",
    "        \n",
    "        # Calculate the discounted price\n",
    "        discounted_price = round(unit_price * (1 - discount), 2)\n",
    "        return discounted_price, discount\n",
    "\n",
    "    # Apply profit margin and discount calculation to each row\n",
    "    data['ProfitMargin'] = data['UnitPrice'].apply(generate_profit_margin)\n",
    "    data['DiscountedPrice'], data['DiscountPct'] = zip(*data.apply(lambda x: calculate_discounted_price(x['UnitPrice'], x['ProfitMargin']), axis=1))\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    data.to_csv(output_file, index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "profit_margins_and_discounts_file = set_profit_margins_and_discounts(df)\n",
    "profit_margins_and_discounts_file\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T19:16:56.440058500Z",
     "start_time": "2024-05-11T19:16:55.896840800Z"
    }
   },
   "id": "9e5f84f9c9ac5ce3",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting Bundles"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63856b03148d62ce"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Aggregate Transctions\n",
    "def aggregate_transactions(df):\n",
    "     transactions = df.groupby([\"InvoiceNo\",\"CustomerID\"]).agg({\"StockCode\": lambda s : list(set(s))})\n",
    "     return transactions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:09:50.979218600Z",
     "start_time": "2024-05-15T04:09:50.916114600Z"
    }
   },
   "id": "89354e31520cb504",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data = pd.read_csv(\"datasets/high_value_transactions.csv\")\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T22:22:28.487222100Z",
     "start_time": "2024-05-09T22:22:28.071043100Z"
    }
   },
   "id": "e31ba7a8efba1591",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_bundles(df):\n",
    "    hbasket = aggregate_transactions(df)\n",
    "    freqItemSet, rules = fpgrowth(hbasket['StockCode'].values, minSupRatio=0.01, minConf=0.9)\n",
    "    print('Number of rules generated: ', len(rules))\n",
    "    \n",
    "    associations = pd.DataFrame(rules, columns=['basket', 'next_product', 'proba'])\n",
    "    associations = associations.sort_values(by='proba', ascending=False)\n",
    "    \n",
    "    itemsets = pd.DataFrame({'itemset': freqItemSet})\n",
    "    itemsets['support'] = itemsets['itemset'].apply(lambda x: hbasket[hbasket['StockCode'].apply(lambda y: set(x).issubset(set(y)))].shape[0] / len(hbasket))\n",
    "    itemsets = itemsets[itemsets['itemset'].apply(lambda x: len(x) > 2)]  # Filter out itemsets with only one item\n",
    "    itemsets = itemsets.sort_values(by='support', ascending=False)  # Sort itemsets by support\n",
    "    \n",
    "    return associations, itemsets\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:08:52.881158500Z",
     "start_time": "2024-05-15T04:08:52.849560Z"
    }
   },
   "id": "98dc580b14a25d61",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import random\n",
    "#Gets an order and returns the most probable next product that the customer will buy\n",
    "def get_next_product(product_bundles, order):\n",
    "    \"\"\"\n",
    "    This function checks if any basket in an associations DataFrame is a subset of the order \n",
    "    and returns a randomly chosen next product if found. Order of elements doesn't matter.\n",
    "\n",
    "    Args:\n",
    "       product_bundles (pandas.DataFrame): DataFrame containing basket-next product associations.\n",
    "        order (set): Set representing the order to check.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The randomly chosen next product if found, otherwise None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert order elements to a set of strings for efficient subset checking\n",
    "    order_set = {str(item) for item in order}\n",
    "\n",
    "\n",
    "    # Initialize an empty list to store next products\n",
    "    next_products = []\n",
    "\n",
    "    # Iterate through each basket in the DataFrame\n",
    "    for basket, next_product, _ in product_bundles.values:\n",
    "        basket_set = set(basket)\n",
    "\n",
    "        # Check if the basket is a subset of the order (regardless of order)\n",
    "        if basket_set.issubset(order_set):\n",
    "            next_products.append(next_product)\n",
    "\n",
    "    # If next products are found, randomly choose one item and return\n",
    "    if next_products:\n",
    "        product = random.choice(next_products)\n",
    "        return product\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T07:52:06.967567100Z",
     "start_time": "2024-05-10T07:52:06.920100700Z"
    }
   },
   "id": "10d031122dc6ad2",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_next_products(product_bundles, order):\n",
    "    \"\"\"\n",
    "    This function checks if any basket in an associations DataFrame is a subset of the order \n",
    "    and returns the first next product found. Order of elements doesn't matter.\n",
    "\n",
    "    Args:\n",
    "        product_bundles (pandas.DataFrame): DataFrame containing basket-next product associations.\n",
    "        order (set): Set representing the order to check.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The first next product found, or None if no match is found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert order elements to a set of strings for efficient subset checking\n",
    "    order_set = {str(item) for item in order}\n",
    "\n",
    "    # Iterate through each basket in the DataFrame\n",
    "    for basket, next_product, _ in product_bundles.values:\n",
    "        basket_set = set(basket)\n",
    "\n",
    "        # Check if the basket is a subset of the order (regardless of order)\n",
    "        if basket_set.issubset(order_set):\n",
    "            return next_product\n",
    "\n",
    "    # If no match is found, return None\n",
    "    print(\"No match found\")\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T09:14:38.738059200Z",
     "start_time": "2024-05-10T09:14:38.659487800Z"
    }
   },
   "id": "8820d204d745fdfa",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_discount_info(df, stock_codes):\n",
    "    \"\"\"\n",
    "    Calculate discount price and discount percentage for given stock codes.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing stock code information.\n",
    "        stock_codes (set or str): Set or string of stock codes to retrieve discount info for.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are stock codes and values are dictionaries\n",
    "              containing discount price and discount percentage.\n",
    "    \"\"\"\n",
    "    # Convert stock_codes to a set if it's not already\n",
    "    if isinstance(stock_codes, str):\n",
    "        stock_codes = {stock_codes}\n",
    "    elif not isinstance(stock_codes, set):\n",
    "        stock_codes = set(stock_codes)\n",
    "\n",
    "    # Initialize an empty dictionary to store discount info\n",
    "    discount_info = {}\n",
    "\n",
    "    # Iterate through each stock code\n",
    "    for code in stock_codes:\n",
    "        # Retrieve the row corresponding to the stock code\n",
    "        row = df[df['StockCode'] == code]\n",
    "\n",
    "        # Check if the row exists\n",
    "        if not row.empty:\n",
    "            # Extract relevant information\n",
    "            discount_price = row['DiscountedPrice'].values[0]\n",
    "            discount_pct = row['DiscountPct'].values[0]\n",
    "\n",
    "            # Store discount info in the dictionary\n",
    "            discount_info[code] = {'DiscountedPrice': discount_price, 'DiscountPct': discount_pct}\n",
    "        else:\n",
    "            # If the stock code is not found, add None values to the dictionary\n",
    "            discount_info[code] = {'DiscountedPrice': None, 'DiscountPct': None}\n",
    "\n",
    "    return discount_info\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T09:00:38.412227300Z",
     "start_time": "2024-05-10T09:00:38.286417200Z"
    }
   },
   "id": "51d770581fa6ef3a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "high = pd.read_csv(\"datasets/high_value_transactions.csv\")\n",
    "nurture = pd.read_csv(\"datasets/nurture_transactions.csv\")\n",
    "risk = pd.read_csv(\"datasets/risk_transactions.csv\")\n",
    "risk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:08:16.174531600Z",
     "start_time": "2024-05-15T04:08:13.623461500Z"
    }
   },
   "id": "eb2b11bdf9097af5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# import pandas as pd\n",
    "\n",
    "def get_bundlesets(high_bundle, risk_bundle, nurture_bundle):\n",
    "  \"\"\"\n",
    "  This function takes three DataFrames (high_bundle, risk_bundle, nurture_bundle)\n",
    "  and generates association rules and frequent itemsets (as CSV files) for each.\n",
    "\n",
    "  Args:\n",
    "      high_bundle (pandas.DataFrame): DataFrame containing high-potential customer data.\n",
    "      risk_bundle (pandas.DataFrame): DataFrame containing risk customer data.\n",
    "      nurture_bundle (pandas.DataFrame): DataFrame containing nurture customer data.\n",
    "  \"\"\"\n",
    "\n",
    "  bundle_data = {\"high_value\": high_bundle, \"risk\": risk_bundle, \"nurture\": nurture_bundle}\n",
    "\n",
    "  for bundle_name, bundle_df in bundle_data.items():\n",
    "    associations, itemsets = get_bundles(bundle_df.copy())\n",
    "\n",
    "    # Save associations to CSV\n",
    "    associations.to_csv(f\"{bundle_name}_associations.csv\", index=False)\n",
    "\n",
    "    # Save itemsets to CSV\n",
    "    itemsets.to_csv(f\"{bundle_name}_itemsets.csv\", index=False)\n",
    "\n",
    "    print(f\"Bundle '{bundle_name}' associations and itemsets saved to CSV files.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:09:13.071435200Z",
     "start_time": "2024-05-15T04:09:13.024537600Z"
    }
   },
   "id": "5ed35b81ba1aa5d6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "get_bundlesets(high,risk,nurture)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:18:44.784372700Z",
     "start_time": "2024-05-15T04:10:16.628949500Z"
    }
   },
   "id": "644c581ec41cdca5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#Bundled Discounts\n",
    "def apply_bundle_discount(bundle, discount_df):\n",
    "    \"\"\"\n",
    "    Apply discounts to each item in a product bundle and return the final price.\n",
    "\n",
    "    Parameters:\n",
    "    - bundle (list): List of product IDs in the bundle.\n",
    "    - discount_df (DataFrame): DataFrame containing product IDs and their discounts.\n",
    "\n",
    "    Returns:\n",
    "    - final_price (float): Final price of the bundle after applying discounts.\n",
    "    \"\"\"\n",
    "    final_price = 0\n",
    "    \n",
    "    # Iterate through each item in the bundle\n",
    "    for item in bundle:\n",
    "        # Look up the discount for the item in the discount DataFrame\n",
    "        item_discount = discount_df.loc[discount_df['ProductID'] == item, 'Discount'].values\n",
    "        \n",
    "        # If the item is found in the discount DataFrame, apply the discount\n",
    "        if len(item_discount) > 0:\n",
    "            item_discount = item_discount[0]  # Extract the discount value\n",
    "            # Assume original price of the item is 0 if not found in discount DataFrame\n",
    "            original_price = discount_df.loc[discount_df['ProductID'] == item, 'Price'].values[0]\n",
    "            # Apply the discount to the original price of the item\n",
    "            discounted_price = original_price * (1 - item_discount)\n",
    "            # Add the discounted price to the final price\n",
    "            final_price += discounted_price\n",
    "        else:\n",
    "            print(f\"Discount not found for item {item}. Assuming original price.\")\n",
    "\n",
    "    return final_price\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:46:13.149010200Z",
     "start_time": "2024-05-10T11:46:13.088202400Z"
    }
   },
   "id": "ca68bda24f596cf8",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "discounts = pd.read_csv(\"datasets/profit_margins_and_discounts.csv\")\n",
    "discounts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:48:16.721939100Z",
     "start_time": "2024-05-10T11:48:16.607770600Z"
    }
   },
   "id": "a55dc918f427417f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def calculate_order_prices(discount_df, order):\n",
    "  \"\"\"\n",
    "  Calculate total order price with and without discounts (considering prices only).\n",
    "\n",
    "  Args:\n",
    "      discount_df (pandas.DataFrame): DataFrame containing stock code information \n",
    "          (StockCode, UnitPrice, DiscountedPrice, DiscountPct, ProfitMargin).\n",
    "      order (set): Set of strings representing stock codes in the order.\n",
    "\n",
    "  Returns:\n",
    "      tuple: A tuple containing two floats:\n",
    "          - Total price without discounts (sum of unit prices).\n",
    "          - Total price with discounts (sum of discounted prices, handling missing values).\n",
    "  \"\"\"\n",
    "\n",
    "  # Convert order set to a list for easier merging\n",
    "  order_list = list(order)\n",
    "\n",
    "  # Create a temporary DataFrame with order stock codes\n",
    "  order_df = pd.DataFrame({'StockCode': order_list})\n",
    "\n",
    "  # Merge order with discount information\n",
    "  merged_df = order_df.merge(discount_df[['StockCode', 'UnitPrice', 'DiscountedPrice']], how='left', on='StockCode')\n",
    "\n",
    "  # Handle missing discount information (assuming UnitPrice is always available)\n",
    "  merged_df['DiscountedPrice'] = merged_df['DiscountedPrice'].fillna(merged_df['UnitPrice'])\n",
    "\n",
    "  # Total price without discounts (sum of unit prices)\n",
    "  total_price_no_discount = merged_df['UnitPrice'].sum()\n",
    "\n",
    "  # Total price with discounts (sum of discounted prices, handling missing values)\n",
    "  total_price_with_discount = merged_df['DiscountedPrice'].fillna(0).sum()\n",
    "\n",
    "  return total_price_no_discount, total_price_with_discount\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T12:02:09.287269500Z",
     "start_time": "2024-05-10T12:02:09.262618100Z"
    }
   },
   "id": "9906362539e451f0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_order_prices(discount_df, order):\n",
    "  \"\"\"\n",
    "  Calculate total order price with and without discounts (considering prices only).\n",
    "  Also print individual item prices and their discount prices.\n",
    "\n",
    "  Args:\n",
    "      discount_df (pandas.DataFrame): DataFrame containing stock code information \n",
    "          (StockCode, UnitPrice, DiscountedPrice, DiscountPct, ProfitMargin).\n",
    "      order (set): Set of strings representing stock codes in the order.\n",
    "\n",
    "  Returns:\n",
    "      tuple: A tuple containing two floats:\n",
    "          - Total price without discounts (sum of unit prices).\n",
    "          - Total price with discounts (sum of discounted prices, handling missing values).\n",
    "  \"\"\"\n",
    "\n",
    "  # Convert order set to a list for easier merging\n",
    "  order_list = list(order)\n",
    "\n",
    "  # Create a temporary DataFrame with order stock codes\n",
    "  order_df = pd.DataFrame({'StockCode': order_list})\n",
    "\n",
    "  # Merge order with discount information\n",
    "  merged_df = order_df.merge(discount_df[['StockCode', 'UnitPrice', 'DiscountedPrice']], how='left', on='StockCode')\n",
    "\n",
    "  # Handle missing discount information (assuming UnitPrice is always available)\n",
    "  merged_df['DiscountedPrice'] = merged_df['DiscountedPrice'].fillna(merged_df['UnitPrice'])\n",
    "\n",
    "  # Loop through each row in the merged DataFrame (representing an item)\n",
    "  for idx, row in merged_df.iterrows():\n",
    "    stock_code = row['StockCode']\n",
    "    unit_price = row['UnitPrice']\n",
    "    discounted_price = row['DiscountedPrice']\n",
    "\n",
    "    # Print individual item and discount information\n",
    "    print(f\"Stock Code: {stock_code}\")\n",
    "    print(f\"  - Unit Price: ${unit_price:.2f}\")\n",
    "    print(f\"  - Discounted Price: ${discounted_price:.2f}\")\n",
    "\n",
    "  # Calculate total price without discounts (sum of unit prices)\n",
    "  total_price_no_discount = merged_df['UnitPrice'].sum()\n",
    "\n",
    "  # Total price with discounts (sum of discounted prices, handling missing values)\n",
    "  total_price_with_discount = merged_df['DiscountedPrice'].fillna(0).sum()\n",
    "\n",
    "  return total_price_no_discount, total_price_with_discount\n",
    "\n",
    "# Sample discount DataFrame (replace with your actual data)\n",
    "# discount_df = pd.DataFrame({'StockCode': [22917, 22919, 22921, 22916],\n",
    "#                            'UnitPrice': [11.00, 12.50, 12.50, 13.10],\n",
    "#                            'DiscountedPrice': [8.76, None, 10.99, 12.45],\n",
    "#                            'DiscountPct': [0.2, None, 0.1, 0.05],\n",
    "#                            'ProfitMargin': [0.3, 0.2, 0.2, 0.15]})\n",
    "# \n",
    "# # Sample order (set of stock codes)\n",
    "# order = {22917, 22919, 22921}  # Include a non-existent code for testing\n",
    "# \n",
    "# # Calculate and print order prices\n",
    "# total_price_no_discount, total_price_with_discount = calculate_order_prices(discount_df, order)\n",
    "# print(f\"\\nTotal Price Without Discounts: ${total_price_no_discount:.2f}\")\n",
    "# print(f\"Total Price With Discounts: ${total_price_with_discount:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:06:08.824622200Z",
     "start_time": "2024-05-15T04:06:08.748460400Z"
    }
   },
   "id": "48cbf9f20eb4f548",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "order = {\"22917\", \"22919\", \"22921\", \"22916\"}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:06:12.176725100Z",
     "start_time": "2024-05-15T04:06:12.129072800Z"
    }
   },
   "id": "63d74d8deff76fc4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "total_price_no_discount, total_price_with_discount =calculate_order_prices(discounts,order)\n",
    "print(total_price_no_discount)\n",
    "print(total_price_with_discount)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T12:08:43.130542700Z",
     "start_time": "2024-05-10T12:08:43.079374500Z"
    }
   },
   "id": "d2333847c1072b7e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "#Without csv\n",
    "def get_bundle_info(segment_name):\n",
    "    # Read the product bundles CSV file for the given segment\n",
    "    bundles_filename = f\"{segment_name}_itemsets.csv\"\n",
    "    bundles_df = pd.read_csv(bundles_filename)\n",
    "\n",
    "    # Get the first 10 bundles\n",
    "    first_10_bundles = bundles_df['itemset'].head(10)\n",
    "\n",
    "    # Read the products CSV file\n",
    "    products_df = pd.read_csv(\"products.csv\")\n",
    "\n",
    "    # Create a dictionary to map stock codes to descriptions\n",
    "    stock_code_to_description = dict(zip(products_df['StockCode'], products_df['Description']))\n",
    "\n",
    "    bundle_info = []\n",
    "\n",
    "    for bundle_str in first_10_bundles:\n",
    "        # Split the bundle string into individual stock codes and remove extra whitespaces\n",
    "        bundle_stock_codes = [code.strip().strip(\"'\") for code in bundle_str.strip('{}').split(',')]\n",
    "      \n",
    "\n",
    "        # Initialize variables to store information about the bundle\n",
    "        bundle_description = []\n",
    "        actual_price = 0\n",
    "        discounted_price = 0\n",
    "\n",
    "        for stock_code in bundle_stock_codes:\n",
    "            # Find the description for the current stock code\n",
    "            description = stock_code_to_description.get(stock_code)\n",
    "            if description:\n",
    "                # Find the product information for the current stock code\n",
    "                product_info = products_df[products_df['StockCode'] == stock_code]\n",
    "\n",
    "                # Get the unit price, discounted price, and discount percentage\n",
    "                unit_price = float(product_info.iloc[0]['UnitPrice'])\n",
    "                discount_pct = float(product_info.iloc[0]['DiscountPct'])\n",
    "\n",
    "                # Calculate the discounted price\n",
    "                discounted_price += unit_price * (1 - discount_pct)\n",
    "\n",
    "                # Add the description to the bundle description\n",
    "                bundle_description.append(description)\n",
    "\n",
    "                # Add the unit price to the actual price\n",
    "                actual_price += unit_price\n",
    "\n",
    "        # Format the bundle description as a string\n",
    "        bundle_description_str = ', '.join(bundle_description)\n",
    "\n",
    "        # Generate a random UUID for the bundle ID\n",
    "        bundle_id = str(uuid.uuid4())\n",
    "\n",
    "        # Create a dictionary for the bundle information\n",
    "        bundle_info.append({\n",
    "            'id': bundle_id,\n",
    "            'bundle': bundle_description_str,\n",
    "            'actual_price': actual_price,\n",
    "            'discounted_price': discounted_price\n",
    "        })\n",
    "\n",
    "    return bundle_info\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T04:34:20.184068200Z",
     "start_time": "2024-05-15T04:34:20.105398400Z"
    }
   },
   "id": "e58d08b6bf604f7a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "def get_bundle_info(segment_names):\n",
    "    \"\"\"\n",
    "    Retrieve information about product bundles for multiple segments.\n",
    "\n",
    "    Args:\n",
    "        segment_names (list): A list of segment names for which to retrieve bundle information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are segment names and values are DataFrames containing information about\n",
    "            the product bundles for each segment. Each DataFrame is also saved to a CSV file.\n",
    "\n",
    "    This function reads CSV files containing product bundles for the specified segments. It then retrieves\n",
    "    information about the bundles, including their descriptions, actual prices, and discounted prices, by querying\n",
    "    a separate CSV file containing information about individual products. The discounted prices are rounded to\n",
    "    2 decimal places.\n",
    "    \"\"\"\n",
    "\n",
    "    bundle_info_dict = {}\n",
    "\n",
    "    for segment_name in segment_names:\n",
    "        # Read the product bundles CSV file for the current segment\n",
    "        bundles_filename = f\"{segment_name}_itemsets.csv\"\n",
    "        bundles_df = pd.read_csv(bundles_filename)\n",
    "\n",
    "        # Get the first 10 bundles\n",
    "        first_10_bundles = bundles_df['itemset'].head(10)\n",
    "\n",
    "        # Read the products CSV file\n",
    "        products_df = pd.read_csv(\"products.csv\")\n",
    "\n",
    "        # Create a dictionary to map stock codes to descriptions\n",
    "        stock_code_to_description = dict(zip(products_df['StockCode'], products_df['Description']))\n",
    "\n",
    "        bundle_info = []\n",
    "\n",
    "        for bundle_str in first_10_bundles:\n",
    "            # Split the bundle string into individual stock codes and remove extra whitespaces\n",
    "            bundle_stock_codes = [code.strip().strip(\"'\") for code in bundle_str.strip('{}').split(',')]\n",
    "\n",
    "            # Initialize variables to store information about the bundle\n",
    "            bundle_description = []\n",
    "            actual_price = 0\n",
    "            discounted_price = 0\n",
    "\n",
    "            for stock_code in bundle_stock_codes:\n",
    "                # Find the description for the current stock code\n",
    "                description = stock_code_to_description.get(stock_code)\n",
    "                if description:\n",
    "                    # Find the product information for the current stock code\n",
    "                    product_info = products_df[products_df['StockCode'] == stock_code]\n",
    "\n",
    "                    # Get the unit price, discounted price, and discount percentage\n",
    "                    unit_price = float(product_info.iloc[0]['UnitPrice'])\n",
    "                    discount_pct = float(product_info.iloc[0]['DiscountPct'])\n",
    "\n",
    "                    # Calculate the discounted price\n",
    "                    discounted_price += unit_price * (1 - discount_pct)\n",
    "\n",
    "                    # Add the description to the bundle description\n",
    "                    bundle_description.append(description)\n",
    "\n",
    "                    # Add the unit price to the actual price\n",
    "                    actual_price += unit_price\n",
    "\n",
    "            # Format the bundle description as a string\n",
    "            bundle_description_str = ', '.join(bundle_description)\n",
    "\n",
    "            # Round the discounted price to 2 decimal places\n",
    "            discounted_price = round(discounted_price, 2)\n",
    "\n",
    "            # Generate a random UUID for the bundle ID\n",
    "            bundle_id = str(uuid.uuid4())\n",
    "\n",
    "            # Create a dictionary for the bundle information\n",
    "            bundle_info.append({\n",
    "                'id': bundle_id,\n",
    "                'bundle': bundle_description_str,\n",
    "                'actual_price': actual_price,\n",
    "                'discounted_price': discounted_price\n",
    "            })\n",
    "\n",
    "        # Convert bundle_info to a DataFrame\n",
    "        bundle_info_df = pd.DataFrame(bundle_info)\n",
    "\n",
    "        # Save bundle_info_df to a CSV file\n",
    "        bundle_info_df.to_csv(f\"{segment_name}_bundles_info.csv\", index=False)\n",
    "\n",
    "        # Add the DataFrame to the dictionary\n",
    "        bundle_info_dict[segment_name] = bundle_info_df\n",
    "\n",
    "    return bundle_info_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T05:03:46.568747300Z",
     "start_time": "2024-05-15T05:03:46.474384900Z"
    }
   },
   "id": "340cad13cbb424e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Example usage:\n",
    "segment_names = ['high_value','nurture', 'risk']\n",
    "bundle_info_dict = get_bundle_info(segment_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T05:05:08.280759600Z",
     "start_time": "2024-05-15T05:05:07.986839200Z"
    }
   },
   "id": "6319d81dfd407ef5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import json\n",
    "\n",
    "api_1 = {\n",
    "    \"percent_tiers\": [\n",
    "        {'min_amount': 0, 'discount': 0},  # Tier 1: $0 - $100 (0% discount)\n",
    "        {'min_amount': 101, 'discount': 5},  # Tier 2: $101 - $200 (5% discount)\n",
    "        {'min_amount': 201, 'discount': 10}  # Tier 3: $201 and above (10% discount)\n",
    "    ],\n",
    "    \"fixed_amount_tiers\": [\n",
    "        {'min_amount': 100, 'discount': 5},  # Tier 1: $100 - $200 ($5 discount)\n",
    "        {'min_amount': 201, 'discount': 15},  # Tier 2: $201 - $300 ($15 discount)\n",
    "        {'min_amount': 301, 'discount': 20}  # Tier 3: $301 and above ($20 discount)\n",
    "    ],\n",
    "    \"loyalty_points\": 2,\n",
    "    \"high_value_loyalty_points\": 5,\n",
    "    \"bogd\": True,\n",
    "    \"bundled discount\": True,\n",
    "}\n",
    "\n",
    "# Define the JSON file name\n",
    "json_file_name = 'ddata.json'\n",
    "\n",
    "# Open the JSON file for writing\n",
    "with open(json_file_name, 'w') as file:\n",
    "    json.dump(api_1, file, indent=4)\n",
    "\n",
    "print(f\"Data has been saved to {json_file_name}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T06:22:51.825991900Z",
     "start_time": "2024-05-17T06:22:51.710521300Z"
    }
   },
   "id": "6dc02227414e7259",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import json\n",
    "\n",
    "def dict_to_json(data, file_name):\n",
    "    \"\"\"\n",
    "    Converts a dictionary to a JSON file.\n",
    "\n",
    "    :param data: The dictionary to be converted.\n",
    "    :param file_name: The name of the JSON file to save.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_name, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        print(f\"Data has been saved to {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "api_1 = {\n",
    "    \"percent_tiers\": [\n",
    "        {'min_amount': 0, 'discount': 0},\n",
    "        {'min_amount': 101, 'discount': 5},\n",
    "        {'min_amount': 201, 'discount': 10}\n",
    "    ],\n",
    "    \"fixed_amount_tiers\": [\n",
    "        {'min_amount': 100, 'discount': 5},\n",
    "        {'min_amount': 201, 'discount': 15},\n",
    "        {'min_amount': 301, 'discount': 20}\n",
    "    ],\n",
    "    \"loyalty_points\": 2,\n",
    "    \"high_value_loyalty_points\": 5,\n",
    "    \"bogd\": True,\n",
    "    \"bundled discount\": True,\n",
    "}\n",
    "\n",
    "# Call the function to save the dictionary as a JSON file\n",
    "dict_to_json(api_1, 'dit.json')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T06:35:14.237460500Z",
     "start_time": "2024-05-17T06:35:14.130632400Z"
    }
   },
   "id": "e50aaa8cfd3f6152",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def dict_to_json(data, file_name, api_name):\n",
    "    \"\"\"\n",
    "    Converts a dictionary to a JSON file and saves it to the specified root path.\n",
    "\n",
    "    :param data: The dictionary to be converted.\n",
    "    :param file_name: The name of the JSON file to save.\n",
    "    :param api_name: The root directory where the JSON file will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the root path exists, if not create it\n",
    "        if not os.path.exists(api_name):\n",
    "            os.makedirs(api_name)\n",
    "        \n",
    "        # Create the full file path\n",
    "        file_path = os.path.join(api_name, file_name)\n",
    "        \n",
    "        # Write the data to the JSON file\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        \n",
    "        print(f\"Data has been saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "api_1 = {\n",
    "    \"percent_tiers\": [\n",
    "        {'min_amount': 0, 'discount': 0},\n",
    "        {'min_amount': 101, 'discount': 5},\n",
    "        {'min_amount': 201, 'discount': 10}\n",
    "    ],\n",
    "    \"fixed_amount_tiers\": [\n",
    "        {'min_amount': 100, 'discount': 5},\n",
    "        {'min_amount': 201, 'discount': 15},\n",
    "        {'min_amount': 301, 'discount': 20}\n",
    "    ],\n",
    "    \"loyalty_points\": 2,\n",
    "    \"high_value_loyalty_points\": 5,\n",
    "    \"bogd\": True,\n",
    "    \"bundled discount\": True,\n",
    "}\n",
    "\n",
    "# Call the function to save the dictionary as a JSON file\n",
    "dict_to_json(api_1, 'discount_data.json', 'path/to/save')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f32efe6fe3faebe4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "discount = pd.read_json(\"../api/January_hwDvdMBx54iuegttt4e6wJ/custom_discounts.json\")\n",
    "print(discount)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:15:20.318756300Z",
     "start_time": "2024-05-18T18:15:20.086402800Z"
    }
   },
   "id": "a516c433a05b93bc",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_custom_discounts(api_name):\n",
    "    file_path = os.path.join(api_name, 'custom_discounts.json')\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T20:31:35.325701900Z",
     "start_time": "2024-05-18T20:31:35.279323200Z"
    }
   },
   "id": "a7ed2860a6146c65",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def calculate_percentage_discounted_price(total_price, api_name):\n",
    "    discounts = load_custom_discounts(api_name)\n",
    "    percent_tiers = discounts.get('percent_tiers', [])\n",
    "\n",
    "    applicable_discount = 0\n",
    "    for tier in percent_tiers:\n",
    "        if total_price >= tier['min_amount']:\n",
    "            applicable_discount = tier['discount']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    discount_amount = total_price * (applicable_discount / 100)\n",
    "    discounted_price = total_price - discount_amount\n",
    "    return discounted_price\n",
    "\n",
    "# Example usage:\n",
    "# api_name = \"January_hwDvdMBx54iuegttt4e6wJ\"\n",
    "# total_price = 150\n",
    "# discount = calculate_percentage_discount(total_price, api_name)\n",
    "# print(f\"Percentage Discount: {discount}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T20:38:27.733664800Z",
     "start_time": "2024-05-18T20:38:27.682758700Z"
    }
   },
   "id": "e637e95ba295e688",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def calculate_fixed_amount_discounted_price(total_price, api_name):\n",
    "    discounts = load_custom_discounts(api_name)\n",
    "    fixed_amount_tiers = discounts.get('fixed_amount_tiers', [])\n",
    "\n",
    "    applicable_discount = 0\n",
    "    for tier in fixed_amount_tiers:\n",
    "        if total_price >= tier['min_amount']:\n",
    "            applicable_discount = tier['discount']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    discounted_price = total_price - applicable_discount\n",
    "    return discounted_price\n",
    "\n",
    "# Example usage:\n",
    "# api_name = \"January_hwDvdMBx54iuegttt4e6wJ\"\n",
    "# total_price = 250\n",
    "# discount = calculate_fixed_amount_discount(total_price, api_name)\n",
    "# print(f\"Fixed Amount Discount: {discount}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T20:38:59.820487Z",
     "start_time": "2024-05-18T20:38:59.797326800Z"
    }
   },
   "id": "8b04d6003794b98d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "api_name = \"../api/January_hwDvdMBx54iuegttt4e6wJ\"\n",
    "total_price = 100\n",
    "    \n",
    "percent_discount = calculate_percentage_discounted_price(total_price, api_name)\n",
    "fixed_discount = calculate_fixed_amount_discounted_price(total_price, api_name)\n",
    "    \n",
    "    \n",
    "print(f\"Percentage Discount: {percent_discount}\")\n",
    "print(f\"Fixed Amount Discount: {fixed_discount}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T20:40:00.744405600Z",
     "start_time": "2024-05-18T20:40:00.681721800Z"
    }
   },
   "id": "1b081dfba06cc621",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "api_name = \"../api/January_hwDvdMBx54iuegttt4e6wJ/products_data.csv\"\n",
    "sales = pd.read_csv(api_name)\n",
    "sales"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T22:01:14.942153500Z",
     "start_time": "2024-05-18T22:01:10.050591900Z"
    }
   },
   "id": "8fdde83d29571443",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shortuuid\n",
    "\n",
    "def get_association_info(api_name, segment_names):\n",
    "    \"\"\"\n",
    "    Retrieve association information for multiple segments.\n",
    "\n",
    "    Args:\n",
    "        api_name (str): The name of the API (also the folder name containing the files).\n",
    "        segment_names (list): A list of segment names for which to retrieve association information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are segment names and values are lists of dictionaries containing information about\n",
    "            the associations for each segment.\n",
    "    \"\"\"\n",
    "    association_info_dict = {}\n",
    "\n",
    "    # Path to the products file\n",
    "    products_file_path = os.path.join(api_name, 'products_data.csv')\n",
    "    \n",
    "    # Read the products CSV file\n",
    "    products_df = pd.read_csv(products_file_path)\n",
    "    \n",
    "    # Create a dictionary to map stock codes to descriptions and prices\n",
    "    stock_code_to_info = products_df.set_index('StockCode').to_dict('index')\n",
    "\n",
    "    for segment_name in segment_names:\n",
    "        # Read the association CSV file for the current segment\n",
    "        associations_filename = os.path.join(api_name, f\"{segment_name}_associations.csv\")\n",
    "        associations_df = pd.read_csv(associations_filename)\n",
    "\n",
    "        association_info = []\n",
    "\n",
    "        for _, row in associations_df.iterrows():\n",
    "            basket_str = row['basket']\n",
    "            next_product_str = row['next_product']\n",
    "\n",
    "            # Parse the basket and next_product strings into lists of stock codes\n",
    "            basket_stock_codes = [code.strip().strip(\"'\") for code in basket_str.strip('{}').split(',')]\n",
    "            next_product_stock_codes = [code.strip().strip(\"'\") for code in next_product_str.strip('{}').split(',')]\n",
    "\n",
    "            # Initialize variables to store information about the basket and next product\n",
    "            basket_description = []\n",
    "            next_product_description = []\n",
    "            actual_price = 0\n",
    "            discounted_price = 0\n",
    "            next_product_discounted_price = 0\n",
    "\n",
    "            for stock_code in basket_stock_codes:\n",
    "                if stock_code in stock_code_to_info:\n",
    "                    product_info = stock_code_to_info[stock_code]\n",
    "                    description = product_info['Description']\n",
    "                    unit_price = product_info['UnitPrice']\n",
    "                    discount_pct = product_info['DiscountPct']\n",
    "                    discounted_price += unit_price * (1 - discount_pct)\n",
    "\n",
    "                    basket_description.append(f\"{description} (${unit_price})\")\n",
    "                    actual_price += unit_price\n",
    "\n",
    "            for stock_code in next_product_stock_codes:\n",
    "                if stock_code in stock_code_to_info:\n",
    "                    product_info = stock_code_to_info[stock_code]\n",
    "                    description = product_info['Description']\n",
    "                    unit_price = product_info['UnitPrice']\n",
    "                    discount_pct = product_info['DiscountPct']\n",
    "                    next_product_discounted_price += unit_price * (1 - discount_pct)\n",
    "\n",
    "                    next_product_description.append(f\"{description} (${unit_price * (1 - discount_pct)})\")\n",
    "\n",
    "            # Format the basket and next product descriptions as strings\n",
    "            basket_description_str = ', '.join(basket_description)\n",
    "            next_product_description_str = ', '.join(next_product_description)\n",
    "\n",
    "            # Generate a short UUID for the association ID\n",
    "            association_id = shortuuid.uuid()\n",
    "\n",
    "            # Create a dictionary for the association information\n",
    "            association_info.append({\n",
    "                'id': association_id,\n",
    "                'bundle': basket_description_str,\n",
    "                'discount_bundle': next_product_description_str,\n",
    "                'total_price': actual_price + next_product_discounted_price,\n",
    "                'discounted_price': discounted_price\n",
    "            })\n",
    "\n",
    "        # Add the association information to the dictionary\n",
    "        association_info_dict[segment_name] = association_info\n",
    "\n",
    "    return association_info_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T00:51:25.773564300Z",
     "start_time": "2024-05-19T00:51:25.682623100Z"
    }
   },
   "id": "201e201d49c28645",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shortuuid\n",
    "\n",
    "def get_association_info(api_name, segment_names):\n",
    "    \"\"\"\n",
    "    Retrieve association information for multiple segments.\n",
    "\n",
    "    Args:\n",
    "        api_name (str): The name of the API (also the folder name containing the files).\n",
    "        segment_names (list): A list of segment names for which to retrieve association information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are segment names and values are lists of dictionaries containing information about\n",
    "            the associations for each segment.\n",
    "        pd.DataFrame: A DataFrame containing the combined information for all segments.\n",
    "    \"\"\"\n",
    "    association_info_dict = {}\n",
    "    all_associations = []\n",
    "\n",
    "    # Path to the products file\n",
    "    products_file_path = os.path.join(api_name, 'products_data.csv')\n",
    "    \n",
    "    # Read the products CSV file\n",
    "    products_df = pd.read_csv(products_file_path)\n",
    "    \n",
    "    # Create a dictionary to map stock codes to descriptions and prices\n",
    "    stock_code_to_info = products_df.set_index('StockCode').to_dict('index')\n",
    "\n",
    "    for segment_name in segment_names:\n",
    "        # Read the association CSV file for the current segment\n",
    "        associations_filename = os.path.join(api_name, f\"{segment_name}_associations.csv\")\n",
    "        associations_df = pd.read_csv(associations_filename)\n",
    "\n",
    "        association_info = []\n",
    "\n",
    "        for _, row in associations_df.iterrows():\n",
    "            basket_str = row['basket']\n",
    "            next_product_str = row['next_product']\n",
    "\n",
    "            # Parse the basket and next_product strings into lists of stock codes\n",
    "            basket_stock_codes = [code.strip().strip(\"'\") for code in basket_str.strip('{}').split(',')]\n",
    "            next_product_stock_codes = [code.strip().strip(\"'\") for code in next_product_str.strip('{}').split(',')]\n",
    "\n",
    "            # Initialize variables to store information about the basket and next product\n",
    "            basket_description = []\n",
    "            next_product_description = []\n",
    "            actual_price = 0\n",
    "            next_product_actual_price = 0\n",
    "            next_product_discounted_price = 0\n",
    "\n",
    "            for stock_code in basket_stock_codes:\n",
    "                if stock_code in stock_code_to_info:\n",
    "                    product_info = stock_code_to_info[stock_code]\n",
    "                    description = product_info['Description']\n",
    "                    unit_price = product_info['UnitPrice']\n",
    "\n",
    "                    basket_description.append(f\"{description} (${unit_price})\")\n",
    "                    actual_price += unit_price\n",
    "\n",
    "            for stock_code in next_product_stock_codes:\n",
    "                if stock_code in stock_code_to_info:\n",
    "                    product_info = stock_code_to_info[stock_code]\n",
    "                    description = product_info['Description']\n",
    "                    discounted_price_next_product = product_info['DiscountedPrice']\n",
    "\n",
    "                    next_product_discounted_price += discounted_price_next_product\n",
    "                    next_product_actual_price += discounted_price_next_product  # Use the discounted price as actual price\n",
    "\n",
    "                    next_product_description.append(f\"{description} [FROM  (${next_product_actual_price}) TO(${discounted_price_next_product})]\")\n",
    "\n",
    "            # Format the basket and next product descriptions as strings\n",
    "            basket_description_str = ', '.join(basket_description)\n",
    "            next_product_description_str = ', '.join(next_product_description)\n",
    "\n",
    "            # Generate a short UUID for the association ID\n",
    "            association_id = shortuuid.uuid()\n",
    "\n",
    "            # Create a dictionary for the association information\n",
    "            association_info.append({\n",
    "                'id': association_id,\n",
    "                'bundle': basket_description_str,\n",
    "                'discount_bundle': next_product_description_str,\n",
    "                'total_price': actual_price + next_product_actual_price,\n",
    "                'discounted_price': actual_price + next_product_actual_price - next_product_discounted_price,\n",
    "                'segment': segment_name\n",
    "            })\n",
    "\n",
    "            all_associations.append({\n",
    "                'id': association_id,\n",
    "                'bundle': basket_description_str,\n",
    "                'discount_bundle': next_product_description_str,\n",
    "                'total_price': actual_price + next_product_actual_price,\n",
    "                'discounted_price': actual_price + next_product_discounted_price,\n",
    "                'segment': segment_name\n",
    "            })\n",
    "\n",
    "        # Add the association information to the dictionary\n",
    "        association_info_dict[segment_name] = association_info\n",
    "\n",
    "    # Convert the list of all associations to a DataFrame\n",
    "    all_associations_df = pd.DataFrame(all_associations)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_csv_path = os.path.join(api_name, 'bogd_offers.csv')\n",
    "    all_associations_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    return  all_associations_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:36:09.416061300Z",
     "start_time": "2024-05-19T01:36:09.319289Z"
    }
   },
   "id": "11b36dcd39e92625",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "api_name = \"../api/January_hwDvdMBx54iuegttt4e6wJ\"\n",
    "segment_names = ['high_value','nurture', 'risk']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T00:51:28.473373500Z",
     "start_time": "2024-05-19T00:51:28.415728900Z"
    }
   },
   "id": "aedb4083844f073c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "x3 = get_association_info(api_name, segment_names)\n",
    "x3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:36:13.953288700Z",
     "start_time": "2024-05-19T01:36:13.788554700Z"
    }
   },
   "id": "44388c73ecdd895",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "xc = pd.read_csv(\"train.csv\")\n",
    "xc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:39:59.251388700Z",
     "start_time": "2024-05-20T09:39:53.068902500Z"
    }
   },
   "id": "88dde6a2cfb59336",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "c = xc.groupby(\"Store\").sum()[\"Sales\"].reset_index()\n",
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:41:38.547206800Z",
     "start_time": "2024-05-20T09:41:38.175122200Z"
    }
   },
   "id": "e1f0740be15899d4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "b = c.sort_values(by=\"Sales\",ascending=False)\n",
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:44:13.872645Z",
     "start_time": "2024-05-20T09:44:13.746012200Z"
    }
   },
   "id": "414688c5be78f28d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "stores =xc.loc[xc[\"Store\"]==262]\n",
    "stores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:45:39.130995800Z",
     "start_time": "2024-05-20T09:45:38.891139Z"
    }
   },
   "id": "d007ab29b2160e86",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!pip install --upgrade --quiet  langchain-google-genai pillow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:10:10.564400900Z",
     "start_time": "2024-05-23T18:08:53.631407700Z"
    }
   },
   "id": "36271e461a693a63",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "!pip install -U langchain-google-genai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:44:05.868645400Z",
     "start_time": "2024-05-23T18:43:55.765665900Z"
    }
   },
   "id": "f016002c3c4348c6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "!pip install langchain langchain_community\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:40:13.934619800Z",
     "start_time": "2024-05-23T18:39:50.702232900Z"
    }
   },
   "id": "58e77e991834ade6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:17:59.896742500Z",
     "start_time": "2024-05-24T00:17:54.717039200Z"
    }
   },
   "id": "f6063c67068b211",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:13:08.389999900Z",
     "start_time": "2024-05-23T18:12:58.037005Z"
    }
   },
   "id": "8341b25f94b87276",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "result = llm.invoke(\"Write a ballad about LangChain\")\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:14:43.991562800Z",
     "start_time": "2024-05-23T18:14:36.806977100Z"
    }
   },
   "id": "955c90e654c0832f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "# Replace with your own API Key\n",
    "API_KEY = \"AIzaSyBjPYCxTeXake-2xFrqTteWw0fH4Tppq-E\"\n",
    "\n",
    "def generate_marketing_recommendations(objectives):\n",
    "    # Initialize Langchain client with GoogleGenerativeAI\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    \n",
    "    # Initialize conversation chain\n",
    "    chain = ConversationChain(llm=client)\n",
    "\n",
    "    # Process user input (replace with your NLP processing)\n",
    "    target_audience, desired_outcome = process_objectives(objectives)\n",
    "\n",
    "    # Craft prompts based on objectives\n",
    "    prompt_1 = f\"Recommend marketing strategies to achieve {desired_outcome} for a target audience of {target_audience}\"\n",
    "    prompt_2 = f\"List creative social media content ideas to support the recommended marketing strategies\"\n",
    "\n",
    "    # Interact with Langchain and Gemini Pro\n",
    "    response_1 = client.generate([prompt_1])  # Wrapped prompt in a list\n",
    "    recommendations = response_1.generations[0][0].text  # Access the text of the first generation\n",
    "\n",
    "    response_2 = client.generate([f\"Based on the recommendations, {prompt_2}\"])  # Wrapped prompt in a list\n",
    "    content_ideas = response_2.generations[0][0].text  # Access the text of the first generation\n",
    "\n",
    "    # Present recommendations in a user-friendly way\n",
    "    print(f\"Marketing Recommendations for {desired_outcome} - Target Audience: {target_audience}\")\n",
    "    # print(recommendations)\n",
    "    to_markdown(recommendations)\n",
    "    print(\"\\nCreative Social Media Content Ideas:\")\n",
    "    # print(content_ideas)\n",
    "    to_markdown(content_ideas)\n",
    "\n",
    "# Example function for processing objectives (replace with your NLP implementation)\n",
    "def process_objectives(objectives):\n",
    "    # Extract target audience and desired outcome from user input (objectives)\n",
    "    target_audience = \"Tech Enthusiasts\"  # Replace with NLP processing\n",
    "    desired_outcome = \"Increased brand awareness\"  # Replace with NLP processing\n",
    "\n",
    "    return target_audience, desired_outcome\n",
    "\n",
    "# Example usage\n",
    "objectives = \"Increase brand awareness among young tech enthusiasts\"\n",
    "generate_marketing_recommendations(objectives)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:56:35.834644300Z",
     "start_time": "2024-05-23T18:56:16.202184100Z"
    }
   },
   "id": "88925858efed68aa",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "# Replace with your own API Key\n",
    "API_KEY = \"AIzaSyBjPYCxTeXake-2xFrqTteWw0fH4Tppq-E\"\n",
    "\n",
    "def to_markdown(text):\n",
    "    # Basic conversion to markdown, customize as needed\n",
    "    # For example, converting new lines to markdown bullet points\n",
    "    lines = text.split('\\n')\n",
    "    markdown_text = '\\n'.join(f'* {line.strip()}' if line else '' for line in lines)\n",
    "    return markdown_text\n",
    "\n",
    "def generate_marketing_recommendations(objectives):\n",
    "    # Initialize Langchain client with GoogleGenerativeAI\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    \n",
    "    # Initialize conversation chain\n",
    "    chain = ConversationChain(llm=client)\n",
    "\n",
    "    # Process user input (replace with your NLP processing)\n",
    "    target_audience, desired_outcome = process_objectives(objectives)\n",
    "\n",
    "    # Craft prompts based on objectives\n",
    "    prompt_1 = f\"Recommend marketing strategies to achieve {desired_outcome} for a target audience of {target_audience}\"\n",
    "    prompt_2 = f\"List creative social media content ideas to support the recommended marketing strategies\"\n",
    "\n",
    "    # Interact with Langchain and Gemini Pro\n",
    "    response_1 = client.generate([prompt_1])  # Wrapped prompt in a list\n",
    "    recommendations = response_1.generations[0][0].text  # Access the text of the first generation\n",
    "\n",
    "    response_2 = client.generate([f\"Based on the recommendations, {prompt_2}\"])  # Wrapped prompt in a list\n",
    "    content_ideas = response_2.generations[0][0].text  # Access the text of the first generation\n",
    "\n",
    "    # Present recommendations in a user-friendly way\n",
    "    print(f\"Marketing Recommendations for {desired_outcome} - Target Audience: {target_audience}\")\n",
    "    # Convert recommendations to markdown and print\n",
    "    recommendations_markdown = to_markdown(recommendations)\n",
    "    print(recommendations_markdown)\n",
    "    print(\"\\nCreative Social Media Content Ideas:\")\n",
    "    # Convert content ideas to markdown and print\n",
    "    content_ideas_markdown = to_markdown(content_ideas)\n",
    "    print(content_ideas_markdown)\n",
    "\n",
    "# Example function for processing objectives (replace with your NLP implementation)\n",
    "def process_objectives(objectives):\n",
    "    # Extract target audience and desired outcome from user input (objectives)\n",
    "    target_audience = \"Tech Enthusiasts\"  # Replace with NLP processing\n",
    "    desired_outcome = \"Increased brand awareness\"  # Replace with NLP processing\n",
    "\n",
    "    return target_audience, desired_outcome\n",
    "\n",
    "# Example usage\n",
    "objectives = \"Increase brand awareness among young tech enthusiasts\"\n",
    "generate_marketing_recommendations(objectives)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:59:09.776741500Z",
     "start_time": "2024-05-23T18:58:47.867181200Z"
    }
   },
   "id": "b3c88c3a72106dc",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "!pip install -q -U google-generativeai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:25:09.632327200Z",
     "start_time": "2024-05-23T18:25:01.034679100Z"
    }
   },
   "id": "874b7fc950ea6036",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:16:30.892728Z",
     "start_time": "2024-05-24T00:16:30.749179100Z"
    }
   },
   "id": "97e5502a0ec74151",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:26:09.559372200Z",
     "start_time": "2024-05-23T18:26:09.287848900Z"
    }
   },
   "id": "aef9bb4254018165",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "# Replace with your own API Key\n",
    "API_KEY = \"AIzaSyBjPYCxTeXake-2xFrqTteWw0fH4Tppq-E\"\n",
    "\n",
    "def to_markdown(text):\n",
    "    # Basic conversion to markdown, customize as needed\n",
    "    # For example, converting new lines to markdown bullet points\n",
    "    lines = text.split('\\n')\n",
    "    markdown_text = '\\n'.join(f'* {line.strip()}' if line else '' for line in lines)\n",
    "    return markdown_text\n",
    "\n",
    "def generate_marketing_recommendations(objectives):\n",
    "    # Initialize Langchain client with GoogleGenerativeAI\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    \n",
    "    # Initialize conversation chain\n",
    "    chain = ConversationChain(llm=client)\n",
    "\n",
    "    # Process user input (replace with your NLP processing)\n",
    "    target_audience, desired_outcome = process_objectives(objectives)\n",
    "\n",
    "    # Craft prompts based on objectives\n",
    "    prompt_1 = f\"Recommend marketing strategies to achieve {desired_outcome} for a target audience of {target_audience}\"\n",
    "    prompt_2 = f\"List creative social media content ideas to support the recommended marketing strategies\"\n",
    "\n",
    "    # Interact with Langchain and Gemini Pro\n",
    "    response_1 = client.generate([prompt_1])  # Wrapped prompt in a list\n",
    "    recommendations = response_1.generations[0][0].text  # Access the text of the first generation\n",
    "\n",
    "    response_2 = client.generate([f\"Based on the recommendations, {prompt_2}\"])  # Wrapped prompt in a list\n",
    "    content_ideas = response_2.generations[0][0].text  # Access the text of the first generation\n",
    "\n",
    "    # Present recommendations in a user-friendly way using IPython display\n",
    "    display_markdown(f\"Marketing Recommendations for {desired_outcome} - Target Audience: {target_audience}\", raw=True)\n",
    "    # Convert recommendations to markdown and display\n",
    "    recommendations_markdown = to_markdown(recommendations)\n",
    "    display_markdown(recommendations_markdown, raw=True)\n",
    "    display_markdown(\"\\nCreative Social Media Content Ideas:\", raw=True)\n",
    "    # Convert content ideas to markdown and display\n",
    "    content_ideas_markdown = to_markdown(content_ideas)\n",
    "    display_markdown(content_ideas_markdown, raw=True)\n",
    "\n",
    "# Example function for processing objectives (replace with your NLP implementation)\n",
    "def process_objectives(objectives):\n",
    "    # Extract target audience and desired outcome from user input (objectives)\n",
    "    target_audience = \"Tech Enthusiasts\"  # Replace with NLP processing\n",
    "    desired_outcome = \"Increased brand awareness\"  # Replace with NLP processing\n",
    "\n",
    "    return target_audience, desired_outcome\n",
    "\n",
    "# Example usage\n",
    "objectives = \"Increase brand awareness among young tech enthusiasts\"\n",
    "generate_marketing_recommendations(objectives)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T19:03:57.679439600Z",
     "start_time": "2024-05-23T19:03:40.190535500Z"
    }
   },
   "id": "3aa109d0b227c1a8",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "API_KEY = \"AIzaSyBjPYCxTeXake-2xFrqTteWw0fH4Tppq-E\"\n",
    "genai.configure(api_key=API_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:15:30.837668600Z",
     "start_time": "2024-05-24T00:15:30.649305200Z"
    }
   },
   "id": "a5361938a5e64f29",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:28:08.505512Z",
     "start_time": "2024-05-23T18:28:08.194875600Z"
    }
   },
   "id": "7ffc97f6728094b7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "response = model.generate_content(\"What is the meaning of life?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:28:44.396018100Z",
     "start_time": "2024-05-23T18:28:33.543463100Z"
    }
   },
   "id": "cebb0b72fa32b720",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "to_markdown(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:29:04.378732100Z",
     "start_time": "2024-05-23T18:29:04.104062300Z"
    }
   },
   "id": "958698a0b0ed878c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "api_name =pd.read_csv(\"../api/datasets\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cda2b8e4054fc7f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sales = pd.read_csv(\"../api/datasets/sample_sales_data.csv\")\n",
    "print(sales)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:04:44.909026Z",
     "start_time": "2024-05-24T00:04:39.070778500Z"
    }
   },
   "id": "dd4666095f3cffc",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "promos = pd.read_csv(\"../api/datasets/promotional_days.csv\")\n",
    "print(promos)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:07:45.327286800Z",
     "start_time": "2024-05-24T00:07:45.048420800Z"
    }
   },
   "id": "c2e130214ae18b7c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "# Replace with your own API Key\n",
    "API_KEY = \"AIzaSyBjPYCxTeXake-2xFrqTteWw0fH4Tppq-E\"\n",
    "\n",
    "def to_markdown(text):\n",
    "    \"\"\"Convert text to markdown format.\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    markdown_text = '\\n'.join(f'* {line.strip()}' if line else '' for line in lines)\n",
    "    return markdown_text\n",
    "\n",
    "def generate_sales_recommendations(sales_forecast, promo_days):\n",
    "    \"\"\"Generate actionable sales recommendations based on sales forecast and promotion days.\"\"\"\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    chain = ConversationChain(llm=client)\n",
    "\n",
    "    # Process the sales forecast data\n",
    "    forecast_text = f\"The sales forecasting model predicts the following sales for the month:\\n\"\n",
    "    for index, row in sales_forecast.iterrows():\n",
    "        forecast_text += f\"Date: {row['InvoiceDate']}, Quantity: {row['Quantity']}\\n\"\n",
    "\n",
    "    # Process the promotion days data\n",
    "    promo_text = \"Promotion days recommendations:\\n\"\n",
    "    for index, row in promo_days.iterrows():\n",
    "        promo_text += f\"Date: {row['Date']}, Promotion Type: {row['Promotion Type']}\\n\"\n",
    "\n",
    "    # Craft the detailed prompt\n",
    "    detailed_prompt = (f\"As an e-commerce retailer, based on the sales forecast and promotion days \"\n",
    "                       f\"recommendations provided below, generate actionable recommendations on how to best \"\n",
    "                       f\"optimize sales during this month. Explain in detail, providing business strategic planning \"\n",
    "                       f\"ideas and practical steps to implement these strategies effectively.\\n\\n\"\n",
    "                       f\"Sales Forecast:\\n{forecast_text}\\n\\n\"\n",
    "                       f\"Promotion Days:\\n{promo_text}\\n\\n\"\n",
    "                       f\"Write a maximum of 500 words in explanation and business strategic planning ideas.\")\n",
    "\n",
    "    # Generate recommendations using Google Generative AI\n",
    "    response = client.generate([detailed_prompt])\n",
    "    recommendations = response.generations[0][0].text\n",
    "\n",
    "    # Display recommendations in markdown format using IPython\n",
    "    display_markdown(\"## Sales Forecast Recommendations\", raw=True)\n",
    "    display_markdown(to_markdown(recommendations), raw=True)\n",
    "\n",
    "# Example sales forecast and promotion days data\n",
    "import pandas as pd\n",
    "\n",
    "sales_forecast = pd.DataFrame({\n",
    "    'Unnamed: 0': range(20, 44),\n",
    "    'InvoiceDate': [\"2011-01-04\", \"2011-01-05\", \"2011-01-06\", \"2011-01-07\", \"2011-01-09\", \"2011-01-10\", \n",
    "                    \"2011-01-11\", \"2011-01-12\", \"2011-01-13\", \"2011-01-14\", \"2011-01-16\", \"2011-01-17\", \n",
    "                    \"2011-01-18\", \"2011-01-19\", \"2011-01-20\", \"2011-01-21\", \"2011-01-23\", \"2011-01-24\", \n",
    "                    \"2011-01-25\", \"2011-01-26\", \"2011-01-27\", \"2011-01-28\", \"2011-01-30\", \"2011-01-31\"],\n",
    "    'Quantity': [8626, 19757, 23121, 17131, 8196, 12853, 28429, 10604, 10159, 23125, 4202, 13380, 82935, \n",
    "                 17368, 10477, 15296, 5235, 12008, 15599, 10955, 11306, 9841, 3431, 13388]\n",
    "})\n",
    "\n",
    "promo_days = pd.DataFrame({\n",
    "    'Date': [\"2011-01-11\", \"2011-01-12\", \"2011-01-13\", \"2011-01-14\", \"2011-01-18\", \"2011-01-16\", \"2011-01-23\", \n",
    "             \"2011-01-30\", \"2024-05-15\"],\n",
    "    'Promotion Type': [\"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Lull\", \"Lull\", \"Lull\", \"Lull\"]\n",
    "})\n",
    "\n",
    "# Generate recommendations\n",
    "generate_sales_recommendations(sales_forecast, promo_days)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:18:18.988595Z",
     "start_time": "2024-05-24T00:18:07.508616Z"
    }
   },
   "id": "f0e761b544538210",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "# Replace with your own API Key\n",
    "API_KEY = \"AIzaSyBjPYCxTeXake-2xFrqTteWw0fH4Tppq-E\"\n",
    "\n",
    "def to_markdown(text):\n",
    "    \"\"\"Convert text to markdown format.\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    markdown_text = '\\n'.join(f'* {line.strip()}' if line else '' for line in lines)\n",
    "    return markdown_text\n",
    "\n",
    "def generate_sales_recommendations(sales_forecast, promo_days):\n",
    "    \"\"\"Generate actionable sales recommendations based on sales forecast and promotion days.\"\"\"\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    chain = ConversationChain(llm=client)\n",
    "\n",
    "    # Process the sales forecast data\n",
    "    forecast_text = \"The sales forecasting model predicts the following sales for the month:\\n\"\n",
    "    for index, row in sales_forecast.iterrows():\n",
    "        forecast_text += f\"Date: {row['InvoiceDate']}, Quantity: {row['Quantity']}\\n\"\n",
    "\n",
    "    # Process the promotion days data\n",
    "    promo_text = \"Promotion days recommendations:\\n\"\n",
    "    for index, row in promo_days.iterrows():\n",
    "        promo_text += f\"Date: {row['Date']}, Promotion Type: {row['Promotion Type']}\\n\"\n",
    "\n",
    "    # # Craft the improved detailed prompt\n",
    "    # detailed_prompt = (\n",
    "    #     f\"As a world-class consultant and expert in sales optimization and business strategy, you are tasked with \"\n",
    "    #     f\"providing actionable recommendations for an e-commerce retailer based on the sales forecast and promotion \"\n",
    "    #     f\"days provided below. Your recommendations should be understandable and implementable, addressing the store \"\n",
    "    #     f\"owner directly. Provide a detailed action plan with practical steps to implement these strategies effectively.\\n\\n\"\n",
    "    #     f\"### Sales Forecast:\\n{forecast_text}\\n\"\n",
    "    #     f\"### Promotion Days:\\n{promo_text}\\n\\n\"\n",
    "    #     f\"Please include:\\n\"\n",
    "    #     f\"- **Specific strategies to optimize sales during peak and lull periods**\\n\"\n",
    "    #     f\"- **Tactical marketing and promotional activities for each recommended action**\\n\"\n",
    "    #     f\"- **Suggestions for inventory management and customer engagement**\\n\"\n",
    "    #     f\"- **Any other expert insights that could help maximize sales and efficiency**\\n\\n\"\n",
    "    #     f\"Write a maximum of 500 words in explanation and business strategic planning ideas.\"\n",
    "    # )\n",
    "      # Improved and detailed prompt with specific questions\n",
    "    detailed_prompt = (\n",
    "        f\"As a leading e-commerce consultant, I require your assistance in crafting a winning sales strategy \"\n",
    "        f\"to maximize revenue for the upcoming period. Here's the provided sales forecast and promotion days data:\\n\\n\"\n",
    "        f\"### Sales Forecast:\\n{forecast_text}\\n\"\n",
    "        f\"### Promotion Days:\\n{promo_text}\\n\\n\"\n",
    "        f\"Considering this information, please provide:\\n\"\n",
    "        f\"- **Specific strategies to optimize sales during peak and lull periods.**\\n\"\n",
    "        f\"    - What targeted marketing campaigns can be implemented for each period?\\n\"\n",
    "        f\"    - How can we leverage email marketing and social media promotions effectively?\\n\"\n",
    "        f\"- **Two implementable marketing campaign themes with detailed action plans.**\\n\"\n",
    "        f\"    - Include budget allocation suggestions for each campaign.\\n\"\n",
    "        f\"- **Inventory management strategies to ensure stock availability during peak periods.**\\n\"\n",
    "        f\"- **Customer engagement tactics to drive repeat purchases and brand loyalty.**\\n\"\n",
    "        f\"Please provide a clear and concise response suitable for a store owner, focusing on actionable steps.\"\n",
    "    )\n",
    "\n",
    "    # Generate recommendations using Google Generative AI\n",
    "    response = client.generate([detailed_prompt])\n",
    "    recommendations = response.generations[0][0].text\n",
    "\n",
    "    # Display recommendations in markdown format using IPython\n",
    "    display_markdown(\"## Sales Forecast Recommendations\", raw=True)\n",
    "    recommendations_markdown = to_markdown(recommendations)\n",
    "    display_markdown(recommendations_markdown, raw=True)\n",
    "\n",
    "# Example sales forecast and promotion days data\n",
    "import pandas as pd\n",
    "\n",
    "sales_forecast = pd.DataFrame({\n",
    "    'Unnamed: 0': range(20, 44),\n",
    "    'InvoiceDate': [\"2011-01-04\", \"2011-01-05\", \"2011-01-06\", \"2011-01-07\", \"2011-01-09\", \"2011-01-10\", \n",
    "                    \"2011-01-11\", \"2011-01-12\", \"2011-01-13\", \"2011-01-14\", \"2011-01-16\", \"2011-01-17\", \n",
    "                    \"2011-01-18\", \"2011-01-19\", \"2011-01-20\", \"2011-01-21\", \"2011-01-23\", \"2011-01-24\", \n",
    "                    \"2011-01-25\", \"2011-01-26\", \"2011-01-27\", \"2011-01-28\", \"2011-01-30\", \"2011-01-31\"],\n",
    "    'Quantity': [8626, 19757, 23121, 17131, 8196, 12853, 28429, 10604, 10159, 23125, 4202, 13380, 82935, \n",
    "                 17368, 10477, 15296, 5235, 12008, 15599, 10955, 11306, 9841, 3431, 13388]\n",
    "})\n",
    "\n",
    "promo_days = pd.DataFrame({\n",
    "    'Date': [\"2011-01-11\", \"2011-01-12\", \"2011-01-13\", \"2011-01-14\", \"2011-01-18\", \"2011-01-16\", \"2011-01-23\", \n",
    "             \"2011-01-30\", \"2024-05-15\"],\n",
    "    'Promotion Type': [\"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Lull\", \"Lull\", \"Lull\", \"Lull\"]\n",
    "})\n",
    "\n",
    "# Generate recommendations\n",
    "generate_sales_recommendations(sales_forecast, promo_days)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:30:27.360923600Z",
     "start_time": "2024-05-24T00:30:17.305419700Z"
    }
   },
   "id": "dc5ef8d25d3abd1b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def generate_customer_recommendations(segmentation, objectives):\n",
    "  \"\"\"\n",
    "  Analyzes customer segmentation data and generates creative recommendations using generative AI.\n",
    "\n",
    "  Args:\n",
    "      segmentation: A dictionary containing customer segment percentages (e.g., high_value=20, nurturing=50, risk=30).\n",
    "      objectives: A dictionary containing business objectives (e.g., increase_high_value=15, increase_satisfaction=None).\n",
    "\n",
    "  Returns:\n",
    "      A list of recommendation strings generated by Gemini Pro.\n",
    "  \"\"\"\n",
    "\n",
    "  client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "  chain = ConversationChain(llm=client)\n",
    "\n",
    "  # Craft the prompt with segmentation data and objectives\n",
    "  prompt = (\n",
    "      f\"You are a business consultant specializing in customer relationship management (CRM) strategies. \"\n",
    "      f\"I'd like you to analyze the following customer segmentation data and provide creative recommendations \"\n",
    "      f\"to achieve specific business objectives:\\n\\n\"\n",
    "      f\"Customer Segmentation:\\n\"\n",
    "      f\"{segmentation}\\n\\n\"\n",
    "      f\"Business Objectives:\\n\"\n",
    "      f\"{objectives}\\n\\n\"\n",
    "      f\"Please generate a list of actionable recommendations that are innovative, \"\n",
    "      f\"creative, and outside-the-box for each objective. Focus on strategies that \"\n",
    "      f\"leverage customer insights and segmentation effectively. Aim for at least 3 \"\n",
    "      f\"recommendations per objective.\"\n",
    "  )\n",
    "\n",
    "  # Generate recommendations using Gemini Pro\n",
    "  response = client.generate([prompt])\n",
    "  recommendations = response.generations[0][0].text\n",
    "\n",
    "  return recommendations.split(\"\\n\\n\")  # Split the response by line breaks\n",
    "\n",
    "# Example customer segmentation data\n",
    "customer_segmentation = {\n",
    "    \"high_value\": 20,\n",
    "    \"nurturing\": 50,\n",
    "    \"risk\": 30,\n",
    "}\n",
    "\n",
    "# Example business objectives\n",
    "business_objectives = {\n",
    "    \"increase_high_value\": 15,\n",
    "    \"increase_satisfaction\": None,\n",
    "}\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = generate_customer_recommendations(customer_segmentation, business_objectives)\n",
    "print(recommendations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T00:50:14.393097700Z",
     "start_time": "2024-05-24T00:50:07.158765400Z"
    }
   },
   "id": "dfa88c0746be98bd",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_sales_recommendations(sales_optimization_objectives, sales_forecast, promo_days):\n",
    "    # Prepare sales prompt\n",
    "    sales_prompt = \"\"\"\n",
    "    As a world-class business consultant AI agent, your task is to analyze the sales forecast data and provide actionable insights relevant to strategic planning for an e-commerce retailer. Describe the sales forecast data, highlighting any key insights that can aid in strategic planning.\n",
    "\n",
    "    1. Sales Forecast Data Description:\n",
    "       - Provide a detailed overview of the sales forecast data, including historical trends, seasonal variations, and any anomalies or patterns observed.\n",
    "       - Highlight key metrics such as total sales volume, revenue projections, and product performance.\n",
    "       - Identify any external factors (e.g., market trends, economic conditions) that may impact sales.\n",
    "\n",
    "    2. Insights for Strategic Planning:\n",
    "       - Analyze the sales forecast data to identify trends, opportunities, and potential risks for the business.\n",
    "       - Provide actionable insights that align with the retailer's business objectives, such as increasing revenue, expanding market share, or improving customer retention.\n",
    "       - Recommend strategic initiatives based on the analysis, such as product launches, pricing adjustments, or targeted marketing campaigns.\n",
    "\n",
    "    3. Marketing Campaigns for Peak and Lull Periods:\n",
    "       - Based on the identified peak and lull periods in the sales forecast data, create two marketing campaigns: one for the lull periods and another for the peak periods.\n",
    "       - For the peak periods, design a campaign that capitalizes on increased consumer demand, leveraging promotions, discounts, and exclusive offers to drive sales.\n",
    "       - For the lull periods, devise a campaign to stimulate sales and maintain customer engagement during slower periods. Consider offering limited-time promotions, bundle deals, or loyalty rewards to incentivize purchases.\n",
    "       - Provide specific details for each campaign, including target audience, messaging, creative assets, and promotion channels (e.g., email marketing, social media, paid advertising).\n",
    "       - Ensure that the campaigns are actionable and tailored to the retailer's target market and brand identity.\n",
    "\n",
    "    4. Promotional Days or Offers:\n",
    "       - Evaluate whether it's appropriate to designate lull periods as promotional days or offer special promotions during these times.\n",
    "       - Consider factors such as customer behavior, competitive landscape, and business objectives when making recommendations.\n",
    "       - Offer expert advice on the potential impact of promotional days or offers on sales, customer satisfaction, and long-term brand perception.\n",
    "       - Provide insights into the optimal timing, duration, and format of promotions to maximize effectiveness and ROI.\n",
    "\n",
    "    5. Expert Advice and Business Objectives Alignment:\n",
    "       - Offer expert advice on how the retailer can leverage sales forecast data and marketing strategies to achieve its business objectives.\n",
    "       - Emphasize the importance of aligning marketing efforts with overarching business goals, such as driving revenue growth, increasing customer lifetime value, or enhancing brand loyalty.\n",
    "       - Recommend KPIs and performance metrics to track the success of marketing campaigns and measure their impact on business outcomes.\n",
    "       - Provide actionable recommendations for continuous improvement and optimization based on real-time data analysis and market feedback.\n",
    "\n",
    "    Your insights and recommendations should empower the e-commerce retailer to make informed decisions and execute effective marketing strategies that drive sales and foster long-term success.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Google Generative AI\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    chain = ConversationChain(llm=client)\n",
    "    \n",
    "    # Generate recommendations using Google Generative AI\n",
    "    response = client.generate([sales_prompt])\n",
    "    recommendations = response.generations[0][0].text\n",
    "\n",
    "    return recommendations\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df8cd0ade2c91be",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import pandas as pd\n",
    "\n",
    "def generate_sales_recommendations(sales_optimization_objectives, sales_forecast, promo_days):\n",
    "    # Prepare sales prompt\n",
    "    sales_prompt = f\"\"\"\n",
    "    As a world-class business consultant AI agent, your task is to analyze the sales forecast data and provide actionable insights relevant to strategic planning for an e-commerce retailer. Describe the sales forecast data, highlighting any key insights that can aid in strategic planning.\n",
    "     sales forecast data : {sales_forecast}\n",
    "     promo periods : {promo_days}\n",
    "     objectives : {sales_optimization_objectives}\n",
    "\n",
    "    1. Sales Forecast Data Description:\n",
    "       - Provide a detailed overview of the sales forecast data, including historical trends, seasonal variations, and any anomalies or patterns observed.\n",
    "       - Highlight key metrics such as total sales volume, revenue projections, and product performance.\n",
    "       - Identify any external factors (e.g., market trends, economic conditions) that may impact sales.\n",
    "      \n",
    "\n",
    "    2. Insights for Strategic Planning:\n",
    "       - Analyze the sales forecast data to identify trends, opportunities, and potential risks for the business.\n",
    "       - Provide actionable insights that align with the retailer's business objectives, such as increasing revenue, expanding market share, or improving customer retention.\n",
    "       - Recommend strategic initiatives based on the analysis, such as product launches, pricing adjustments, or targeted marketing campaigns.\n",
    "\n",
    "    3. Marketing Campaigns for Peak and Lull Periods:\n",
    "       - Based on the identified peak and lull periods in the sales forecast data, create two marketing campaigns: one for the lull periods and another for the peak periods.\n",
    "       - For the peak periods, design a campaign that capitalizes on increased consumer demand, leveraging promotions, discounts, and exclusive offers to drive sales.\n",
    "       - For the lull periods, devise a campaign to stimulate sales and maintain customer engagement during slower periods. Consider offering limited-time promotions, bundle deals, or loyalty rewards to incentivize purchases.\n",
    "       - Provide specific details for each campaign, including target audience, messaging, creative assets, and promotion channels (e.g., email marketing, social media, paid advertising).\n",
    "       - Ensure that the campaigns are actionable and tailored to the retailer's target market and brand identity.\n",
    "\n",
    "    4. Promotional Days or Offers:\n",
    "       - Evaluate whether it's appropriate to designate lull periods as promotional days or offer special promotions during these times.\n",
    "       - Consider factors such as customer behavior, competitive landscape, and business objectives when making recommendations.\n",
    "       - Offer expert advice on the potential impact of promotional days or offers on sales, customer satisfaction, and long-term brand perception.\n",
    "       - Provide insights into the optimal timing, duration, and format of promotions to maximize effectiveness and ROI.\n",
    "\n",
    "    5. Expert Advice and Business Objectives Alignment:\n",
    "       - Offer expert advice on how the retailer can leverage sales forecast data and marketing strategies to achieve its business objectives.\n",
    "       - Emphasize the importance of aligning marketing efforts with overarching business goals, such as driving revenue growth, increasing customer lifetime value, or enhancing brand loyalty.\n",
    "       - Recommend KPIs and performance metrics to track the success of marketing campaigns and measure their impact on business outcomes.\n",
    "       - Provide actionable recommendations for continuous improvement and optimization based on real-time data analysis and market feedback.\n",
    "\n",
    "    Your insights and recommendations should empower the e-commerce retailer to make informed decisions and execute effective marketing strategies that drive sales and foster long-term success.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Google Generative AI\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    chain = ConversationChain(llm=client)\n",
    "    \n",
    "    # Generate recommendations using Google Generative AI\n",
    "    response = client.generate([sales_prompt])\n",
    "    recommendations = response.generations[0][0].text\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# Sample data\n",
    "sales_forecast_data = pd.DataFrame({\n",
    "    'Unnamed: 0': range(20, 44),\n",
    "    'InvoiceDate': [\"2011-01-04\", \"2011-01-05\", \"2011-01-06\", \"2011-01-07\", \"2011-01-09\", \"2011-01-10\", \n",
    "                    \"2011-01-11\", \"2011-01-12\", \"2011-01-13\", \"2011-01-14\", \"2011-01-16\", \"2011-01-17\", \n",
    "                    \"2011-01-18\", \"2011-01-19\", \"2011-01-20\", \"2011-01-21\", \"2011-01-23\", \"2011-01-24\", \n",
    "                    \"2011-01-25\", \"2011-01-26\", \"2011-01-27\", \"2011-01-28\", \"2011-01-30\", \"2011-01-31\"],\n",
    "    'Quantity': [8626, 19757, 23121, 17131, 8196, 12853, 28429, 10604, 10159, 23125, 4202, 13380, 82935, \n",
    "                 17368, 10477, 15296, 5235, 12008, 15599, 10955, 11306, 9841, 3431, 13388]\n",
    "})\n",
    "\n",
    "promo_days_data = pd.DataFrame({\n",
    "    'Date': [\"2011-01-11\", \"2011-01-12\", \"2011-01-13\", \"2011-01-14\", \"2011-01-18\", \"2011-01-16\", \"2011-01-23\", \n",
    "             \"2011-01-30\", \"2024-05-15\"],\n",
    "    'Promotion Type': [\"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Lull\", \"Lull\", \"Lull\", \"Lull\"]\n",
    "})\n",
    "\n",
    "# Sample sales optimization objectives\n",
    "sales_optimization_objectives = \"\"\"\n",
    "- Drive sales growth and maximize revenue.\n",
    "- Optimize inventory levels.\n",
    "- Implement competitive pricing strategies.\n",
    "- Enhance conversion rates.\n",
    "- Increase average order value.\n",
    "- Boost sales through effective promotions and discounts.\n",
    "- Tailor marketing campaigns to specific customer segments.\n",
    "\"\"\"\n",
    "\n",
    "# Generate sales recommendations\n",
    "sales_recommendations = generate_sales_recommendations(sales_optimization_objectives, sales_forecast_data, promo_days_data)\n",
    "\n",
    "print(\"Sales Recommendations:\")\n",
    "print(sales_recommendations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T02:34:39.778954Z",
     "start_time": "2024-05-24T02:34:24.300061900Z"
    }
   },
   "id": "b9dfd90b536cb2ec",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "def generate_customer_segmentation_recommendations(customer_optimization_objectives, customer_segmentation_insights, promo_periods, custom_discounts):\n",
    "    # Prepare customer segmentation prompt\n",
    "    customer_segmentation_prompt = f\"\"\"\n",
    "    As a top-tier business consultant AI agent, your role is to analyze the customer segmentation results for an e-commerce retailer and develop actionable strategies to reach objectives by targeting specific customer segments. Additionally, evaluate custom offers that could be given to customers during promotional periods.\n",
    "    Customer : Insights{customer_segmentation_insights}\n",
    "    Promo periods: {promo_periods}\n",
    "       Custom Discounts: {custom_discounts}\n",
    "       Reailor Objectives :{customer_optimization_objectives}\n",
    "\n",
    "    1. Customer Segmentation Results:\n",
    "       \n",
    "       - Provide an overview of the customer segmentation results, including the identified customer segments and their characteristics.\n",
    "   - Describe each customer segment in terms of demographics, behavior, preferences, and purchasing patterns.\n",
    "   - Highlight the proportion of each segment within the customer base and any notable trends or insights observed.\n",
    "\n",
    "    2. Actionable Strategies to Reach Objectives:\n",
    "       - Based on the identified customer segments and the retailer's objectives, develop actionable strategies to reach objectives by targeting these segments.\n",
    "       - Align each strategy with specific customer objectives, such as increasing customer acquisition, improving retention rates, or maximizing customer lifetime value.\n",
    "       - Recommend personalized marketing tactics, product offerings, and customer experiences tailored to each segment's unique needs and preferences.\n",
    "       - Provide insights into how these strategies can drive business growth and enhance overall customer satisfaction and loyalty.\n",
    "\n",
    "    3. Evaluation of Custom Offers for Promotional Periods:\n",
    "       - Evaluate custom offers that could be given to customers during promotional periods to incentivize purchases and drive sales.\n",
    "   - Consider factors such as customer segmentation, promotional goals, and budget constraints when designing custom offers.\n",
    "   - Recommend a variety of promotional offers tailored to different customer segments, including discounts, bundle deals, free shipping, loyalty rewards, and exclusive perks.\n",
    "   - Assess the potential impact of each offer on customer engagement, conversion rates, and revenue generation.\n",
    "   - Provide expert advice on the optimal timing, duration, and execution of promotional campaigns to maximize effectiveness and ROI.\n",
    "\n",
    "    Your insights and recommendations should empower the e-commerce retailer to implement targeted marketing strategies that resonate with different customer segments, driving engagement, loyalty, and sales growth. Additionally, your evaluation of custom offers should enable the retailer to execute impactful promotional campaigns that drive results and align with business objectives.They should be actionable and detailed\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Google Generative AI\n",
    "    client = GoogleGenerativeAI(model=\"gemini-pro\", api_key=API_KEY)\n",
    "    chain = ConversationChain(llm=client)\n",
    "    \n",
    "    # Generate recommendations using Google Generative AI\n",
    "    response = client.generate([customer_segmentation_prompt])\n",
    "    recommendations = response.generations[0][0].text\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Sample data\n",
    "customer_segmentation_insights = \"\"\"\n",
    "Customer Segmentation Insights:\n",
    "- High-Value Customers: This segment represents 20% of our customer base and consists of our most valuable and loyal customers. They frequently make purchases, have high average order values.\n",
    "- Nurture Segment: The nurture segment comprises 20% of our customer base. These customers show potential for growth and loyalty but require nurturing.\n",
    "- Risk of Churning: Approximately 60% of our customer base falls into the risk of churning segment. These customers show signs of reduced engagement or have not made recent purchases, indicating a higher likelihood of churning.\n",
    "\"\"\"\n",
    "\n",
    "promo_periods = pd.DataFrame({\n",
    "    'Date': [\"2011-01-11\", \"2011-01-12\", \"2011-01-13\", \"2011-01-14\", \"2011-01-18\", \"2011-01-16\", \"2011-01-23\", \n",
    "             \"2011-01-30\", \"2024-05-15\"],\n",
    "    'Promotion Type': [\"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Peak\", \"Lull\", \"Lull\", \"Lull\", \"Lull\"]\n",
    "})\n",
    "\n",
    "\n",
    "custom_discounts = {\n",
    "    \"percent_tiers\": [\n",
    "        {'min_amount': 0, 'discount': 0},  # Tier 1: $0 - $100 (0% discount)\n",
    "        {'min_amount': 101, 'discount': 5},  # Tier 2: $101 - $200 (5% discount)\n",
    "        {'min_amount': 201, 'discount': 10}  # Tier 3: $201 and above (10% discount)\n",
    "    ],\n",
    "    \"fixed_amount_tiers\": [\n",
    "        {'min_amount': 100, 'discount': 5},  # Tier 1: $100 - $200 ($5 discount)\n",
    "        {'min_amount': 201, 'discount': 15},  # Tier 2: $201 - $300 ($15 discount)\n",
    "        {'min_amount': 301, 'discount': 20}  # Tier 3: $301 and above ($20 discount)\n",
    "    ],\n",
    "    \"loyalty_points\": 2,\n",
    "    \"high_value_loyalty_points\": 5,\n",
    "    \"bogd\": True, #Buy one get one discounted\n",
    "    \"bundled discount\": True,\n",
    "}\n",
    "\n",
    "\n",
    "customer_optimization_objectives = \"\"\"\n",
    "- Increase customer satisfaction and loyalty.\n",
    "- Provide a personalized shopping experience.\n",
    "- Ensure a seamless user experience across all platforms.\n",
    "- Deliver excellent customer support.\n",
    "- Develop and maintain effective loyalty programs.\n",
    "- Continuously gather and act on customer feedback.\n",
    "- Ensure secure and easy transactions.\n",
    "\"\"\"\n",
    "\n",
    "# Generate customer segmentation recommendations\n",
    "customer_segmentation_recommendations = generate_customer_segmentation_recommendations(customer_optimization_objectives, customer_segmentation_insights, promo_periods, custom_discounts)\n",
    "\n",
    "print(\"Customer Segmentation Recommendations:\")\n",
    "print(customer_segmentation_recommendations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T02:48:16.808362300Z",
     "start_time": "2024-05-24T02:48:04.822194100Z"
    }
   },
   "id": "6c5f062418717322",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2907e9ee77e396dd",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
